%\documentclass[a4paper,12pt]{article} 
\documentclass[14pt]{extarticle}
\usepackage[T1,T2A]{fontenc} 
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amssymb,amsfonts,amsmath,mathtext,cite,enumerate,float}
\usepackage[hidelinks]{hyperref}
\usepackage{graphicx}
\usepackage{adjustbox}
\usepackage {indentfirst}
\usepackage{amsmath}
\usepackage{indentfirst}
\usepackage{bbm}
%\usepackage[linesnumbered,boxed]{algorithm2e}

\usepackage{geometry} % Меняем поля страницы
\geometry{left=3cm}% левое поле
\geometry{right=1cm}% правое поле
\geometry{top=2cm}% верхнее поле
\geometry{bottom=2cm}% нижнее поле

\newcommand{\argmin}{\operatornamewithlimits{argmin}}
%\newcommand{\min}{\operatornamewithlimits{min}}
%для русского псевдокода
%\SetKwInput{KwData}{Входные данные}
%\SetKwInput{KwResult}{Результат}
%\SetKwInput{KwIn}{Входные данные}
%\SetKwInput{KwOut}{Выходные данные}
%\SetKwIF{If}{ElseIf}{Else}{если}{тогда}{иначе\ если}{иначе}{конец\ условия}
%\SetKwFor{While}{до\ тех\ пор,\ пока}{выполнять}{конец\ цикла}
%\SetKw{KwTo}{от}
%\SetKw{KwRet}{возвратить}
%\SetKw{Return}{возвратить}
%\SetKwBlock{Begin}{начало\ блока}{конец\ блока}
%\SetKwSwitch{Switch}{Case}{Other}{Проверить\ значение}{и\ выполнить}{вариант}{в\ противном\ случае}{конец\ варианта}{конец\ проверки\ значений}
%\SetKwFor{For}{цикл}{выполнять}{конец\ цикла}
%\SetKwFor{ForEach}{для\ каждого}{выполнять}{конец\ цикла}
%\SetKwRepeat{Repeat}{повторять}{до\ тех\ пор,\ пока}
%\SetAlgorithmName{Алгоритм}{алгоритм}{Список алгоритмов}

\usepackage{algorithm}
\usepackage{algpseudocode}

\renewcommand{\listalgorithmname}{Список алгоритмов}
\floatname{algorithm}{Алгоритм}

\algrenewcommand\algorithmicwhile{\textbf{До тех пока}}
\algrenewcommand\algorithmicdo{\textbf{выполнять}}
\algrenewcommand\algorithmicrepeat{\textbf{Повторять}}
\algrenewcommand\algorithmicuntil{\textbf{Пока}}
\algrenewcommand\algorithmicend{\textbf{Конец}}
\algrenewcommand\algorithmicif{\textbf{Если}}
\algrenewcommand\algorithmicelse{\textbf{иначе}}
\algrenewcommand\algorithmicthen{\textbf{тогда}}
\algrenewcommand\algorithmicfor{\textbf{Цикл}}
\algrenewcommand\algorithmicforall{\textbf{Выполнить для всех}}
\algrenewcommand\algorithmicfunction{\textbf{Функция}}
\algrenewcommand\algorithmicprocedure{\textbf{Процедура}}
\algrenewcommand\algorithmicloop{\textbf{Зациклить}}
\algrenewcommand\algorithmicrequire{\textbf{Вход:}}
\algrenewcommand\algorithmicensure{\textbf{Выход:}}
\algrenewcommand\algorithmicreturn{\textbf{Выход:}}
\algrenewtext{EndWhile}{\textbf{Конец цикла}}
\algrenewtext{EndLoop}{\textbf{Конец зацикливания}}
\algrenewtext{EndFor}{\textbf{Конец цикла}}
\algrenewtext{EndFunction}{\textbf{Конец функции}}
\algrenewtext{EndProcedure}{\textbf{Конец процедуры}}
\algrenewtext{EndIf}{\textbf{Конец условия}}
\algrenewtext{EndFor}{\textbf{Конец цикла}}
\algrenewtext{BeginAlgorithm}{\textbf{Начало алгоритма}}
\algrenewtext{EndAlgorithm}{\textbf{Конец алгоритма}}
\algrenewtext{BeginBlock}{\textbf{Начало блока. }}
\algrenewtext{EndBlock}{\textbf{Конец блока}}
\algrenewtext{ElsIf}{\textbf{иначе если }}




\begin{document}

\begingroup
\fontsize{12pt}{12pt}\selectfont
\begin{titlepage}
\begin{center}
 
 
   \includegraphics[width=0.5\textwidth]{msu}
   
   Московский государственный университет имени М.В.~Ломоносова\\
   Факультет Вычислительной математики и кибернетики\\
   Кафедра Математических методов прогнозирования
   
    \vspace{5cm}
    {\Large Кудрявцев~Георгий~Алексеевич}  
    \vspace{1cm}
   
    {\Large\bfseries
    Построение ансамбля алгоритмов рекомендаций\\}
   
    \vspace{1cm}
   
    {\large ВЫПУСКНАЯ КВАЛИФИКАЦИОННАЯ РАБОТА}
 
    \vfill
   
    \begin{flushright}
      \textbf{Научный руководитель:}\\
      д.ф-м.н., профессор\\
      Дьяконов Александр Геннадьевич
    \end{flushright}
 
   \vspace{\fill}
   Москва, 2016
\end{center}
\end{titlepage}
\endgroup
%\thispagestyle{empty} % не нумеровать первую страницу

\newpage


%\begin{titlepage}
%\begin{center}
%
%    \bigskip
%    \includegraphics[width=50mm]{titul_cartoon}
%
%    \bigskip
%    Московский государственный университет имени М.\,В.~Ломоносова
%    Факультет Вычислительной математики и кибернетики\\
%    Кафедра Математических методов прогнозирования\\[30mm]
%
%    \textsf{\large
%      ВЫПУСКНАЯ КВАЛИФИКАЦИОННАЯ РАБОТА \\[10mm]
%      \textbf{
%        Построение ансамбля алгоритмов рекомендаций
%      }
%    }\\[30mm]
%
%    \begin{flushright}
%      \parbox{0.5\textwidth}{
%        \raggedleft
%        \textbf{Выполнил:}\\
%        студент 417 группы\\
%        Кудрявцев Георгий Алексеевич\\[5mm]
%        \textbf{Научный руководитель:}\\
%        д.ф-м.н., профессор\\
%        Дьяконов Александр Геннадьевич
%      }
%    \end{flushright}
%
%    \vspace{\fill}
%    Москва, 2015
%\end{center}
%\end{titlepage}
%\thispagestyle{empty} % не нумеровать первую страницу


\tableofcontents % сгенерировать оглавление
\newpage

\begin{center}\textbf{Аннотация} \end{center}
Данная работа посвящена задаче ранжирования по данным с двоичной релевантностью. Был проведен обзор современных факторизационных методов  решения этой задачи, а также  метрик, оценивающих качество ранжирования.  Проведен анализ качества работы алгоритмов на различных наборах данных. Был предложен метод ансамблирования, который стабильно улучшает качество ранжирования. 
\newpage

\section{Введение}


С ростом популярности электронной коммерции, возникла задача помощи пользователям в поиске товаров, которые им понравятся. Одними из инструментов, используемые для решения этой проблемы, являются рекомендательные системы. 

Коллаборативная фильтрация является одним из методов построения рекомендательных систем. Она использует известные оценки или предпочтения  для построения рекомендации пользователям, чьи оценки и предпочтения неизвестны. Идея данного метода состоит в предположении того, что пользователи, имеющие похожие предпочтения в прошлом, будут иметь похожие предпочтения в будущем.



Существует три различных подхода в коллаборативной фильтрации.

Первый подход называется Memory-based. Его идея заключается в вычислении сходства между пользователями или предметами. Соответственно, похожие предметы или пользователи должны иметь похожие оценки или предпочтения.

Второй подход называется Model-based. Его идея заключается в создании моделей при помощи интеллектуального анализа данных и машинного обучения. Модель обучается на реальных данных, например, на истории покупок интернет-магазина, а далее выдает рекомендации для пользователей, чьи предпочтения неизвестны. 

Третий подход -- Hybrid. Его идея заключается в использовании первого и второго подхода, компенсируя недостатки обоих. 


В данной работе будет рассматриваться второй подход.

Также следует упомянуть о таком важном понятии как обратная связь(feedback). Обратной связью некоторого пользователя на предмет называют некоторое событие, по которому можно судить о предпочтении автора. 
Например, это может быть оценка фильма по десятибалльной шкале. Либо клик на описание товара в интернет-магазине.

В коллаборативной фильтрации выделяют два типа обратной связи: с явным откликом(explicit feedback) и неявным откликом(implicit feedback).

 В первом случае пользователь осознано оценивает предмет и производит соответствующий отклик. Например,  оценивает работу интернет-магазина по пятибалльной шкале.

Неявный отклик  обозначает лишь то, что между пользователем и предметом произошло взаимодействие. Например, покупатель зашел на страницу с описанием товара, либо несколько раз посмотрел  видеоролик. Как видно, из этого отклика нельзя выяснить, имеется ли у пользователя положительное или отрицательное предпочтение к предмету, и есть ли оно вообще.

В данной работе будет рассмотрен случай, в котором набор данных состоит только из неявного отклика, причем он будет в бинарном виде. '1'  обозначает наличие взаимодействия с предметом, а '0' его отсутствие.  Такая ситуация возможна в некоторых случаях. Например, дружба между пользователями в социальной сети или история встреч на сайте знакомств. Далее будем считать, что неявный отклик показывает положительное предпочтение пользователя к предмету.


В качестве моделей будет рассмотрен класс факторизационных методов. Их основная идея лежит в представлении предпочтения пользователя к предмету  в виде скалярного произведения их латентных векторов\cite{matrixfactorization}.  Данные методы хорошо себя показали в известном конкурсе Netflix Prize\cite{netflix}.

Также в решении победителей не малую роль сыграл ансамбль алгоритмов, поэтому в данной работе было  решено исследовать, как можно улучшить качество современных факторизационных методов в задаче ранжирования при помощи  построения ансамблей. 

\section{Цель работы}
Целью работы является изучение и сравнение существующих факторизационных алгоритмов ранжирования, а также создание новых, более эффективных методов при помощи построения ансамблей. 


Данная работа  разделена на несколько частей.
\begin{enumerate}
\item Ввод необходимых понятий и обозначений.
\item Обзор современных методов ранжирования.
\item Построение различных ансамблей методов ранжирования.
\item Тестирование и сравнение методов и ансамблей на реальных данных.
\end{enumerate}


\section{Обозначения}

Набор данных R представлен в виде матрицы  размером $|U| \times |I|$, где $U$ - множество пользователей,  $I$ - множество предметов. В дальнейшем обозначим $M = |U| $ и $N = |I|$

Если между пользователем $u$ и предметов $i$ произошел неявный отклик, то $R_{ui}=1$. В противном случае $R_{ui} = 0$. Будем считать, что предмет $i$ релевантен пользователю $u$, если $R_{ui}$ = 1


Обозначим за $rank(u, i)$ номер позиции предмета i в упорядоченном списке, который был получен при помощи метода ранжирования, для пользователя $u$.   

Введем функцию $rel(u, k)$ такую что, $rel(u, k)$ = 1, если предмет, стоящий на $k$ позиции в упорядоченном списке предметов для пользователя $u$, релевантен. В противном случае $rel(u, k)$ = 0.  


Пусть  

$P$ - множество профилей пользователей, 

$Q$ - множество профилей предметов,

$P_u$ - профиль(латентный вектор) пользователя $u$,

$Q_i$ - профиль(латентный вектор) предмета $i$.

Прогноз $f_{ui}$ предпочтения пользователя $u$ предмета $i$  представлен в виде скалярного произведения латентных векторов $P_u$ и $Q_i$, т.е. $f_{ui} = \langle P_u, Q_i \rangle$

Также в дальнейшем будет часто использоваться сигмоида. Обозначим ее за $\sigma(x) = \frac{1}{1 + e^{-x}}$. 
%\section{Постановка задачи}
%
%Дана матрица описаний транзакций R. По ней нужно построить метод ранжирования, который будет для каждого пользователя $u$ выдавать список предметов в порядке релевантности. Будем считать, что предмет $i$ релевантен пользователю $u$, если $R_{ui} =1$.

\section{Критерии качества}
В задаче ранжирования не существует однозначно правильного функционала качества, поэтому было решено использовать сразу несколько.

\subsection{$P@n$}
	Определим эту метрику для одного пользователя.
	\begin{equation*}
		P@n(u) = \frac{1}{N}\sum_{k = 1}^n rel(u, k)
	\end{equation*}
	
	Теперь для всех пользователей.
	\begin{equation*}
		P@n = \frac{1}{M}\sum_{u = 1}^M P@n(u)
	\end{equation*}
	$P@n$ показывает среднюю долю релевантных объектов по всем пользователям.  Недостатком этой метрики является то, что она не учитывает порядок предметов. Например,  если пользователь получил только один релевантный предмет, то для этой метрики не важно, был ли он в начале списка или в конце. 
\subsection{$1call@n$}
	Определим эту метрику для одного пользователя.
	\begin{equation*}
		1call@n(u) = [\sum_{k = 1}^n rel(u, k) > 0]
	\end{equation*}
	
	Теперь для всех пользователей.
	\begin{equation*}
		P@n = \frac{1}{M}\sum_{u = 1}^M 1call@n(u)
	\end{equation*}
	$1call@n$ показывает долю пользователей, у которых был хотя бы один релевантный предмет. Метрика не учитывает  ни порядок, ни количество релевантных предметов. 
\subsection{$MRR$}
	MRR -- Mean Reciprocal Rank
	
	Пусть $firstrank(u)$  - номер позиции первого релевантного предмета в ранжированном списке для пользователя $u$. Номер позиции в списке начинается с 1.
	\begin{equation*}
		MRR = \frac{1}{M}\sum^{M}_{u=1}\frac{1}{firstrank(u)}	
	\end{equation*}
	
	Эта метрика используется, если рекомендательной системе важнее подать пользователю один релевантый предмет в начало списка. 

	 
\subsection{$NDCG@n$}
	NDCG -- Normalized Discounted Cumulative Gain
	
	\begin{equation*}
	\begin{split}
	 & G(u, k) = 2^{rel(u, k)} - 1 \\
	 & D(k) = \frac{1}{log_2(k + 1)} \\
	 & DCG@n(u) = \sum_{k=1}^n G(u, k) D(k) \\
	 & NDCG@n(u) = \frac{DCG@n(u)}{max DCG@n}
	\end{split}			
	\end{equation*}
	
	Эта метрика является популярной в информационном поиске. Она учитывает и порядок, и количество релевантных предметов. Также большим плюсом является то, что $NDCG$ работает в случае различных уровней релевантности.
	
\subsection{$MAP$}
	MAP -- 	Mean Average Precision
	
	
	\begin{equation*}
	\begin{split}
	 & AP@n(u) = \frac{1}{n}\sum_{k=1}^n rel(u, k) P@k(u)  \\
	 & MAP@n = \frac{1}{M}\sum_{k=1}^M AP@n(u) \\
	\end{split}			
	\end{equation*}
	
	Аналогично предыдущей метрике, $MAP$ является достаточно популярной, учитывает и порядок, и количество релевантных предметов.
	
	
%\subsection{$AUC$}

\section{Существующие методы}
В ходе работы были рассмотрены факторизационные методы ранжирования. Их основная идея заключается в представлении пользователей и предметов в виде векторов латентных векторов $P_u$ и $Q_i$. Величина $f_{ui} = \langle P_u, Q_i\rangle$  показывает заинтересованность пользователя $u$ в предмете  $i$. Следовательно, по величине $f_{ui}$ можно ранжировать предметы для конкретного пользователя.
	
Далее приведен список факторизационных методов с их кратким описанием.  
\begin{enumerate}
\item \textbf{CLiMF} --
  Факторизационный метод, который оптимизирует сглаженную версию метрики MRR.\cite{climf}
  	
\item \textbf{MPR\_MF} -- 
  Факторизационный метод, который оптимизирует AUC.\cite{bprmp}
  
\item \textbf{TFMAP} --
   Факторизационный метод, который оптимизирует сглаженную метрику MAP.\cite{tfmap}

\item \textbf{iMF} --
	Факторизационный метод, который оптимизирует взвешенную квадратичную ошибку.\cite{imf} 

\item \textbf{PopRec} --
    Простой метод, который ранжирует предметы по убыванию количества пользователей, для которых данный предмет является релевантным. В результате метод выдает для каждого пользователя один  и тот же ответ.
\end{enumerate}

\subsection{CLiMF}
Данный метод использует в качестве функционала качества MRR. Заметим, что MRR можно переписать в другом виде.
\begin{equation*}
 MRR =\frac{1}{M}\sum_{u=1}^M \sum_{i=1}^N \frac{R_{ui}}{rank(u,i)}\prod_{k=1}^N(1 - R_{uk}[rank(u,k) < rank(u, i)])
\end{equation*}
 Но  MRR не является гладкой функцией, поэтому авторы метода решили оптимизировать сглаженную версию этой метрики. В качестве регуляризатора был взят L2-регуляризатор. В итоге получаем следующий функционал качества.

\begin{equation*}
	F(P, Q) = \sum_{u=1}^M \sum_{i=1}^N [R_{ui}(\ln(\sigma(f_{ui})) + \sum_{k=1}^N \ln(1 - R_{uk}\sigma(f_{uk} - f_{ui})))] - \frac{\lambda}{2}({||U||}^2 + {||V||}^2 ) 
	\end{equation*}	

Далее этот функционал оптимизируется при помощи стохастического градиентного спуска.

\begin{algorithm}[h]
\caption{обучение метода CLiMF}
\begin{algorithmic}[1]
\Require {набор данных R, параметр регуляризации $\lambda$, скорость обучение $\gamma$, 
максимальное число итерации maxiter, длина латентных векторов K}
\Ensure {обученные латентные векторы P, Q}
\For{i = 1 .. M}
\State $N_u = \{i | R_{ui} > 0, 1 \leq i \leq N\}$
\EndFor

инициализируем $U^{(0)}$ и $V^{(0)}$ случайными значениями. t = 0.
\Repeat {} 
\For {$u = 1 .. M$}
		\State $P_u^{(t+1)} = P_u^{(t)} + \gamma \frac{\partial F}{\partial P_u^{(t)}}$
			\For {$i \in N_u$}
				\State 	$Q_i^{(t+1)} = Q_i^{(t)} + \gamma \frac{\partial F}{\partial 	  																						Q_i^{(t)}}$		
			\EndFor	
	\EndFor 
\Until{$t \leq itermax$}

\end{algorithmic}
\label{alg:climf}
\end{algorithm}
\newpage
\subsection{BRP\_MF}  	

Авторы данного метода применили байесовcкий подход к решению задачи ранжирования. Для каждого пользователя $u$  предметы  разбиты на 3 класса: релевантные и нерелевантные предметы, а также предметы с неизвестной релевантностью. Собственно, для последнего класса и нужно  строить ранжирование. 



Пусть $\theta$ - параметр метода. В нашем случае это $P$ и $Q$.  $I_u^+$ -- множество релевантных предметов пользователя u. $I_u^-$ -- множество нерелевантных предметов пользователя u.  $>_u$ - это ранжированный список предметов для пользователя u. Требуется максимизировать вероятность $p(\theta|>_u)$.
\begin{equation*}
\begin{split}
	& p(\theta| >_u) \propto p(>_u| \theta)p(\theta) \\
	& p(>_u| \theta) = \prod_{i, j: \ i \in I_u^+, j \in I_u^-}p(i >_u j| \theta)\\
	& p(\theta) \sim N(0, \lambda I) \\
	& p(i >_u j| \theta) = \sigma(f_{ui} - f_{uj}) 
\end{split}
\end{equation*}

В итоге имеем следующий функционал качества. 
\begin{equation*}
F(P, Q) = \ln(p(\theta| >_u)) = \ln(p(>_u|\theta)p(\theta)) = \sum_{u,i,j: u \in U\ i \in I_u^+\ j \in I_u^-}\ln(\sigma(f_{ui} - f_{uj})) - \lambda {||\theta||} ^ 2
\end{equation*}


Нормальное априорное распределение задает L2-регуляризацию, а сигмоида позволяет легко рассчитывать производные для данного функционала. Авторами  было показано, что данный алгоритм оптимизирует AUC.

\begin{algorithm}[h]
\caption{обучение метода BRP\_MP}
\begin{algorithmic}[1]
\Require {набор данных R, параметр регуляризации $\lambda$, скорость обучение $\gamma$, 
максимальное число итерации maxiter, длина латентных векторов K}
\Ensure {обученные латентные векторы P, Q}
\State {Инициализируем $\theta$ случайными значениями, t = 0}
\State $|R|$ - общее число взаимодействий пользователей с предметами.
\Repeat {} 
	\State {берем случайную тройку $(u, i,j)$, где $u \in U, i \in I_u^+, j \in I_u^-$} 
	\State {$\theta = \theta + \alpha \big( \frac{1}{1 + e ^{(f_{ui} - f_{uj})}}  
	\frac{\partial}{\partial \theta} (f_{ui} - f_{uj}) + \lambda \theta \big)$} 
	\State {t = t + 1}
\Until{$t \leq itermax \cdot |R|$ }

\end{algorithmic}
\label{alg:climf}
\end{algorithm}

\newpage
\subsection{iMF}
За основу iMF был взят оригинальный SVD, функционал качества которого выглядит следующим образом.

\begin{equation*}
F(P, Q) = \sum_{R_{ui} - \textnormal{известно}} (R_{ui} - f_{ui})^2 + \lambda ({||P||} ^ 2 + {||Q||}^2)
\end{equation*}

Недостаток SVD заключается в том, что он показывает плохое качество ранжирования в поставленной задаче.
Чтобы преодолеть данную проблему, авторы метода поменяли функционал качества на следующий.

\begin{equation*}
\begin{split}
& F(P, Q) = \sum_{u, i} c_{ui}(g_{ui} - f_{ui})^2 + \lambda ({||P||} ^ 2 + {||Q||}^2) \\
& g_{ui} =  \begin{cases} 
   0  &\mbox{если } R_{ui} = 0 \\ 
   1 & \mbox{если } R_{ui} > 0 
\end{cases} \\
& c_{ui} = 1 + \alpha R_{ui}
\end{split}
\end{equation*}

Переменная $g_{ui}$ отвечает за неявный отклик между пользователем $u$ и предметом $i$. Т.е. iMF пытается определить не уровень предпочтения пользователя, а неявный отклик. Хотя в нашем случае это одно и тоже. 

Переменная $c_{ui}$ является весом каждого квадратного слагаемого. Чем больше предпочтение, тем больше вес. 

Метод обучается при помощи ALS\cite{matrixfactorization}. 

Пусть Q -- матрица профилей предметов размера $N \times K$, где K - размерность латентного вектора. Каждая $i$-ая  строка равна латентному вектору предмета $i$.  $C^u$ -- диагональная матрица размера $N \times N$, в которой $C_{ii}^u = c_{ui}$. $S_u$ -- вектор размера $N$, в котором $S_{ui} = R_{ui}$. Тогда латентный вектор пользователя $u$ обновляется по следующей формуле.

\begin{equation*}
	P_u = (Q^TC^uQ + \lambda I) ^ {-1}Q^TC^uS_u
\end{equation*} 

Заметим, что $(Q^TC^uQ + \lambda I) = Q^TQ + Q^T(C^u - I)Q $. Матрицу $Q^TQ$ можно вычислить один раз перед обновлением всех латентных векторов пользователей, а в матрице $C^u - I$ количество ненулевых элементов равно числу взаимодействий пользователя $u$ с предметами.

Для латентных векторов рассуждения аналогичны.

\begin{algorithm}[h]
\caption{обучение метода iMF}
\begin{algorithmic}[1]
\Require {набор данных R, параметр регуляризации $\lambda$, скорость обучение $\gamma$, параметр весовых коэффициентов $\alpha$, максимальное число итерации maxiter, длина латентных векторов K}
\Ensure {обученные латентные векторы P, Q}
\State {Инициализируем $P$ и $Q$ случайными значениями, t = 0}
\Repeat {} 
	\State {вычислить матрицу $Q^TQ$} 
	\For {$u = 1 .. M$}
	\State{обновить $P_u$}
	\EndFor
	\State {вычислить матрицу $P^TP$}
	\For {$i = 1 .. N$}
	\State{обновить $Q_i$}
	\EndFor
\Until{$t \leq itermax$}

\end{algorithmic}
\label{alg:climf}
\end{algorithm}


%
%Переменная g_{ui} отвечает за неявный отклик. Будем делать прогноз не на $R_{ui}$, а на $g_{ui}$. Хотя в нашем случае это одно  и то же.  Также заметим, что намного 

\subsection{TFMAP}
Данный метод использует в качестве функционала качества MAP. Заметим, что MAP можно переписать в следующем виде. 
\begin{equation*}
 MAP = \frac{1}{M}\sum_{u=1}^M\frac{\sum_{i=1}^N \frac{R_{ui}}{rank(u, i)} \sum_{j=1}^N R_{uj} 
 [rank(u,j) \leq rank(u, i)]}{\sum_{i=1}^N R_{ui}} 
\end{equation*} 
 
 Далее проводятся рассуждения аналогичные CLiMF. Метрика TFMAP  не является гладкой, следовательно, будем оптимизировать приближенную гладкую версию это метрики. Также добавим L2-регуляризатор.
 
 В итоге получаем  следующую формулу.
 \begin{equation*}
 \begin{split}
 & F(P, Q) = \sum_{u=1}^M \frac{1}{\sum_{i=1}^N R_{ui}} \sum_{i=1}^N R_{ui} \sigma(f_{ij}) \times \sum_{j=1}^N R_{mj} \sigma(f_{uj} - f_{ui}) - \frac{1}{2}\lambda({||P||}^2 + {||Q||}^2)
 \end{split}
 \end{equation*}

Далее возникает проблема подсчета частной производной по $Q_i$. Она вычисляется при помощи следующей формулы. 

\begin{equation*}
 \frac{\partial F}{\partial Q_i} = \sum_{u=1}^M\frac{R_{ui} P_u}{\sum_{i=1}^N R_{ui}}\sum_{j=1}^N \Big(\sigma^{\prime}( f_{ui})\sigma(f_{uj} - f_{ui}) + (\sigma(f_{uj}) - \sigma(f_{ui}))\sigma^{\prime}(f_{uj} - f_{ui}) \Big )  R_{ui} - \lambda Q_i
\end{equation*}

Сложность вычисления этого выражения -- $O(KN|R|)$, где $K$ - размерность латентных векторов, $|R|$ -  количество взаимодействий пользователей с предметами. На практике подсчет такой производной несет большие вычислительные затраты. Для ускорения вычисления выражения авторы заменили $\sum_{i=1}^N$ на $\sum_{i \in B_{u}}$, где $B_{u}$ - множество предметов специального вида. Далее приведен алгоритм построения этого множества.

\begin{algorithm}[h]
\caption{построение множества $B_{u}$}
\begin{algorithmic}[1]
\Require {$Q_i$ и $f_{ui}$ для всех $i$,  размер выборки $n$, $P_u$}
\Ensure {$B_u$}
\State {$B_u = \emptyset$}
\State $B_u = B_u \cup \{i | R_{ui} = 1 \}$
\State $n_u = |B_u|$
\State $p = \min_{i \in B_u} f_{ui}$
\State $S  = \{i |R_{ui} = 0 \} \cap \{i| f_{ui} > p \}$
\State Случайно выбираем подмножество $L \subset S$ размера n.
\State Отсортируем предметы $i \in L$ по убыванию $f_{ui}$
\State Выбираем первые $n_u$ предметов из полученного списка. Обозначим это множество предметов за $B^{-}$
\State $B_u = B_u \cup B^{-}$  
\end{algorithmic}
\label{alg:setB}
\end{algorithm}

Метод обучается при помощи стохастического градиентного спуска.


\section{Эксперименты}

\subsection{Наборы данных}
В исследовании были использованы 4 разных набора данных.

\begin{itemize}
\item \textbf{Epinion}\footnote{\url{https://snap.stanford.edu/data/soc-Epinions1.html}} - социальная сеть, в которой публикуются покупательские отзывы и рецензии на товары и услуги. Каждый участник  решает кому он "доверяет". Следовательно, если пользователь $u$ "доверяет" пользователю $i$, то $R_{ui} = 1$

\item \textbf{Slashdot}\footnote{\url{https://snap.stanford.edu/data/soc-Slashdot0811.html}} - сайт, который предоставляет различные новости в сфере IT. Пользователи сами публикуют новости, в то время как другие пользователи их оценивают и обсуждают. Также данный сайт предоставляет возможность пользователям объявлять друг друга "врагом" или "другом".  $R_{ui}$ = 1, если пользователь $u$ является "другом" или "врагом" пользователя $i$.

\item \textbf{MovieLens}\footnote{\url{http://grouplens.org/datasets/movielens/}} - сайт, в котором пользователи рекомендуют различные фильмы друг другу. Movielens предоставляет возможность ставить оценки фильмам. $R_{ui}$ = 1, если пользователь $u$ поставил оценки фильму $i$. В данной работе использованы два различных набора данных MovieLens: в первом 100000 оценок, во втором 1000000.

\end{itemize}

Перед тем как использовать наборы данных в экспериментах, из них были удалены пользователи, которые взаимодействовали с менее  25 предметами. Это было сделано для преодоления проблемы холодного старта, которым страдают факторизационные методы. 

Далее приведены статистические характеристики каждого набора данных после предобработки. 



\begin{table}[H]
\caption{\label{tab:canonsummary}Статистические характеристики}
%\begin{center}
\resizebox{0.8\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|l|c c c c|}
\hline
Набор данных  & Epinion & Slashdot & MovieLens100k & MovieLens1m\\
\hline
Число ненулевых элементов & 326114 & 573578 & 96963  & 989202 \\
Число пользователей & 4405 & 6992 & 806 & 5549\\
Число предметов & 34777 & 63730 & 1682 & 3702\\
Плотность матрицы & 0.21\% & 0.13\% & 7.15 \% & 4.81 \% \\
Среднее число предметов у пользователя & 51  & 50 & 81 & 106\\
Максимальное число пользователей & 1801 & 2508 & 737 & 2314\\
у одного предмета.  & & & &\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table} 

\subsection{Сравнение методов}
 Сравним качество работы методов ранжирования друг с другом. Для этого проведем два различных  эксперимента. Первый предложен авторами метода CLiMF. Второй является n-карманной кросс-валидацией.
 
Параметры методов были настроены при помощи кросс-валидации на наборе данных Epinion. 

\begin{table}[H]
%\begin{center}
%\resizebox{0.7\textwidth}{!}{\begin{minipage}{\textwidth}
\caption{Параметры методов}
\begin{tabular}{|l|l|}
\hline
Название метода & Параметры\\
\hline 
  CLiMF & $K$ = 10,  $\lambda$ = 0.005, $\gamma$ = 0.001, maxiter = 15\\
\hline
  BPR\_MF & $K$ = 10 ,  $\lambda$ = 0.0025, $\gamma$ = 0.05, maxiter = 300\\
\hline 
  iMF & $K$ = 10,  $\lambda$ = 0.015, $\alpha$ = 1, maxiter = 15\\
\hline 
TFMAP & $K$ = 10, $\lambda$ = 0.001, $\gamma$ = 0.01, $n$ = 100,  maxiter = 15\\
\hline
\end{tabular}
%\end{minipage}}
\end{table} 
 
 
 \subsubsection{Первый эксперимент}
  
 Разобьем набор данных на тренировочную и тестовую выборку случайным образом. В тренировочной выборке у каждого пользователя будет trainK предметов. Остальные предметы лежат в тестовой выборке. Алгоритмы обучаются на тренировочной выборке, а качество работы измеряется на тестовой выборке. Далее такой эксперимент повторяется maxiter раз. Конечным результатом является средняя величина качества работы по метрикам и алгоритмам. 
 
 

 
В таблицах \ref{tab:modsepinion}, \ref{tab:modsslashdot}, \ref{tab:modsmovk} и \ref{tab:movm} показано качество работы алгоритмов на различных данных и параметрах эксперимента.

\begin{table}[H]
\caption{Набор данных Epinion}
\label{tab:modsepinion}
%\begin{center}
\resizebox{0.7\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{trainK = 5, maxiter = 5} & \multicolumn{5}{|c|}{trainK = 10, maxiter = 5}\\
\hline
  & PopRec & CLiMF & BRP\_MF & iMF & TFMAP & PopRec & CLiMF & BRP\_MF & iMF & TFMAP  \\
\hline
P@5 & \textbf{0.1987}& 0.1962 &	0.1960 & 0.1876 & 0.1807 & 0.1837  & 0.1844 & 0.1846 & \textbf{0.2613} &	0.1808 \\
\hline
1call@5 & \textbf{0.5632} & 0.5448 & 0.5450 & 0.5509 & 0.5448 & 0.5189 & 0.5293 & 0.5241 &	\textbf{0.6383} & 0.5212\\
\hline
NDCG@5 & \textbf{0.2222} & 0.2205 & 0.2205 & 0.1980 & 0.2104 & 0.2061 & 0.2064 & 0.1909 &	\textbf{0.2725} &0.2041\\
\hline
MAP@5 & 0.3813 & 0.3769 & 0.3774 & 0.3356 & \textbf{0.3873} & 0.3568 & 0.3572 & 0.3120 &	\textbf{0.4121} & 0.3597\\
\hline
MRR & \textbf{0.4387} & 0.4368 & 0.4383 & 0.3818 & 0.4306 & 0.4113 & 0.4112 & 0.3480 & \textbf{0.4609} &	0.4114\\
\hline
AUC  & 0.8307 & 0.7512 & \textbf{0.8347} & 0.6915 & 0.6407 & 0.8558 & 0.8143 & \textbf{0.8591} &	0.8105 & 0.7310\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table} 


\begin{table}[H]
\caption{Набор данных Slashdot}
\label{tab:modsslashdot}
%\begin{center}
\resizebox{0.7\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{trainK = 5, maxiter = 5} & \multicolumn{5}{|c|}{trainK = 10, maxiter = 5}\\
\hline
  & PopRec & CLiMF & BRP\_MF & iMF & TFMAP & PopRec & CLiMF & BRP\_MF & iMF & TFMAP  \\
\hline
P@5 & 0.1225 & \textbf{0.1227} & 0.1210 & 0.1049 & 0.1153 &  0.1119 & 0.1118 & 0.1128 & \textbf{0.1358} & 0.1128 \\
\hline
1call@5 & \textbf{0.3765} & 0.3774 & 0.3761 & 0.3419 & 0.3592 & 0.3528 & 0.3528 & 0.3531 &	\textbf{0.3928} & 0.3544\\
\hline
NDCG@5 & \textbf{0.1319} & 0.1316 & 0.1309 & 0.1097 & 0.1244 & 0.1210 & 0.1210 & 0.1207 &	\textbf{0.1424} & 0.1215\\
\hline
MAP@5 & 0.2295 & 0.2289 & 	\textbf{0.2297}	& 0.1949 &	0.2194 &  0.2146 & 	0.2147 & 0.2110 &  \textbf{0.2374} &	0.2148\\
\hline
MRR & \textbf{0.2765} & 0.2755 &  0.2761 &  0.2343 &	0.2567 & 0.2602 & 0.2598  & 0.2558 & \textbf{0.2794} & 0.259429\\
\hline
AUC & 0.7770 &	0.6897 & \textbf{0.7850} & 0.5908 & 0.5973 &  0.8127	& 0.7582 & \textbf{0.8182} &	0.6925 & 0.6662\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table} 


\begin{table}[H]
\caption{Набор данных MobieLens 100k}
\label{tab:modsmovk}
%\begin{center}
\resizebox{0.7\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{trainK = 5, maxiter = 5} & \multicolumn{5}{|c|}{trainK = 10, maxiter = 5}\\
\hline
  & PopRec & CLiMF & BRP\_MF & iMF & TFMAP & PopRec & CLiMF & BRP\_MF & iMF & TFMAP  \\
\hline
P@5 & \textbf{0.5309} & 0.5131 & 0.5303 & 0.4625 & 0.2624 &  0.4841 & 0.4821 &  0.4738 & \textbf{0.5307} & 0.4738 \\
\hline
1call@5 & \textbf{0.9431} & 0.9334 &	0.9374 & 0.8970 & 0.7461 & 0.9146 &	0.9141 & 0.9074 & \textbf{0.9292} &	0.8937\\
\hline
NDCG@5 & \textbf{0.5341} & 0.5171 &	0.5319 & 0.4756 & 0.3055 &  0.4934 & 0.4958 & 0.4725 &  \textbf{0.5369} &	0.4802\\
\hline
MAP@5 & \textbf{0.6703} & 0.6512 & 0.6636 & 0.6341 & 0.5452 & 0.6492 & 0.6568 & 0.6117 & \textbf{0.6741} &	0.6212\\
\hline
MRR & \textbf{0.7045} & 0.6970 &	0.7019 & 0.6818 & 0.5931 &  0.6885 & 0.6984 & 0.6474 &	\textbf{0.7139} & 0.6660\\
\hline
AUC & 0.8274 & 0.7572 &	\textbf{0.8288} & 0.6785 & 0.6366 &  0.8530 & 0.8405 & \textbf{0.8531} &	0.8285 & 0.7634\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table} 


\begin{table}[H]
\caption{Набор данных MobieLens 1m}
\label{tab:movm}
%\begin{center}
\resizebox{0.7\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{trainK = 5, maxiter = 5} & \multicolumn{5}{|c|}{trainK = 10, maxiter = 5}\\
\hline
  & PopRec & CLiMF & BRP\_MF & iMF & TFMAP & PopRec & CLiMF & BRP\_MF & iMF & TFMAP  \\
\hline
P@5 & 0.4805 &	\textbf{0.4835} & 0.4797 & 0.4739 & 0.4138 &  0.4903 & 0.4903 &	0.4835 & \textbf{0.5739} & 0.4906\\
\hline
1call@5 & 0.8805 & 0.8704 & \textbf{0.8826} & 0.8707	& 0.8538 &  0.8610 & 0.8610 & 0.8479 & \textbf{0.9302} &	0.8587\\
\hline
NDCG@5 & \textbf{0.4935} & 0.4952 & 0.4923 &	0.4850 & 0.4515 & 0.5011 & 0.5011 &	0.4918 & \textbf{0.5838} & 0.5014\\
\hline
MAP@5 &0.6489 &	\textbf{0.6534} & 0.6484 & 0.6285 & 	0.6626 & 0.6557 & 0.6557 & 0.6151 &  \textbf{0.7088} & 0.6594 \\
\hline
MRR & \textbf{0.6941} & 0.6916 &	0.6930 & 0.6728 & 0.7019 & 0.6903 &	0.6903 & 0.6597 & \textbf{0.7530} & 0.6897\\
\hline
AUC & \textbf{0.8503} & 0.8286 &	0.8488 & 0.7185 & 0.7476 & \textbf{0.8561} &	0.8514 & 0.8556 & 0.8279 & 0.8043\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table} 

Видно, что качество работы методов сильно зависит от параметров проводимого эксперимента. 

При trainK = 5 в среднем лучше работает PopRec. Во многом высокое качество работы PopRec связано с тем, что во всех представленных наборах данных существует большое количество популярных предметов, которые есть почти у каждого пользователя. Например, очередной блокбастер или  популярный блог. С данной проблемой сталкивались авторы других статей \cite{climf, reasonbadwork}.
 
 CLiMF, BRP\_MF и TFMAP всегда имеют качество работы близкое к PopRec. Но в отличие от PopRec, факторизационные методы имеют разные прогнозы предпочтения для разных пользователей.  
 
 В результатах экспериментов также не  было замечено какой-либо хорошей работы CLiMF и TFMAP на метриках MRR и MAP@n соответственно. Причем не один из данных методов не имел самое высокое качество по своему функционалу. 
 
 BRP\_MF почти всегда имеет самый высокий AUC. Но по  эксперименту при параметре trainK = 10 видно,что такой функционал абсолютно не подходит. iMF имеет самое высокое качество на втором эксперименте по всем метрикам, кроме AUC. 

\subsubsection{Второй эксперимент}
 Минусом первого эксперимента является то, что в тренировочной выборке присутствует лишь малая часть от всех данных. Следовательно, имела место ситуация, в которой некоторые методы показывали недостаточно хорошее качество из-за того, что они недообучились.   Поэтому было решено проверить качество работы при помощи n-карманной кросс-валидации. 
 
 В таблицах \ref{tab:2comp1}, \ref{tab:2comp2}, \ref{tab:2comp3} и \ref{tab:2comp4} показано качество работы алгоритмов на различных данных и параметрах эксперимента.
 
\begin{table}[H]
\caption{Набор данных MovieLens 100k}
\label{tab:2comp1}
%\begin{center}
\resizebox{0.7\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{n = 10} & \multicolumn{5}{|c|}{n = 5}\\
\hline
   & PopRec & CLiMF & BRP\_MF & iMF & TFMAP & PopRec & CLiMF & BRP\_MF & iMF & TFMAP  \\
\hline
P@5 &0.1399 & 0.1429 & 0.2672 &	\textbf{0.2972} & 0.1478 & 0.2401 & 0.2468 &	0.3945 & \textbf{0.4476} & 0.257 \\
\hline
1call@5 & 0.4516 & 0.4565 & 0.6947 & \textbf{0.7332} & 0.4354 &  0.6625 & 0.6550 & 0.8461 & \textbf{0.8883} &	0.6153\\
\hline
NDCG@5 & 0.1549 & 0.1592 & 0.2837 & \textbf{0.3220} & 0.1652 & 0.2591 & 0.2611 &	0.4118 & \textbf{0.4782} & 0.2748\\
\hline
MAP@5 & 0.2853 & 0.2934 & 0.4511 & \textbf{0.5043}  & 0.2882 &  0.4245 &	0.4179 & 0.5815 & \textbf{0.6651} & 0.4169\\
\hline
MRR & 0.3413& 0.3451 & 0.5025 & \textbf{0.5568} & 0.3384 &  0.4806 & 0.4711 &0.6335 & \textbf{0.7205} & 0.4624\\
\hline
AUC & 0.8597 & 0.8470 & \textbf{0.9317} & 0.9310 & 0.8503 & 0.8566 &	0.8417 & \textbf{0.9290} & 0.9283 & 0.8471\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table}

\begin{table}[H]
\caption{Набор данных Epinion}
\label{tab:2comp2}
%\begin{center}
\resizebox{0.7\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{n = 5} & \multicolumn{5}{|c|}{n = 10}\\
\hline
   & PopRec & CLiMF & BRP\_MF & iMF & TFMAP & PopRec & CLiMF & BRP\_MF & iMF & TFMAP  \\
\hline
P@5 & 0.0301 & 0.0294 &	0.0557 & \textbf{0.06940} &	0.0273 & 0.0564 & 0.0545 &	0.0999 & \textbf{0.1248} & 0.0548 \\
\hline
1call@5 & 0.1327 & 0.1300 &	0.2267 & \textbf{0.2726} & 0.1213 & 0.2301 & 0.2237 & 0.3532	 & |\textbf{0.4251} & 	0.2221\\
\hline
NDCG@5 & 0.0338 &	0.0332 & 0.0586 &  \textbf{0.0742} & 0.0312 & 0.0636 & 0.0619 &	0.1052 & \textbf{0.1316} &	0.0628 \\
\hline
MAP@5 &  0.0767 & 0.0757 & 0.1210 &	\textbf{0.1515} & 0.0716 &  0.1375 &	0.1353 & 0.1973	& \textbf{0.2438} & 0.1363 \\
\hline
MRR & 0.0999 & 0.0990 &	0.1541 & \textbf{0.1864} & 0.0946 & 0.1703 &	0.1680 & 0.2385 &  \textbf{0.2853} &	0.1687\\
\hline
AUC &0.8690 &  0.7685 &	\textbf{0.9192} & 0.9175 & 0.8607 &  0.8700 & 0.7576 & \textbf{0.9185} & 0.9159 &	0.8615\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table}

\begin{table}[H]
\caption{Набор данных Slashdot}
\label{tab:2comp3}
%\begin{center}
\resizebox{0.7\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{n = 10} & \multicolumn{5}{|c|}{n = 5}\\
\hline
   & PopRec & CLiMF & BRP\_MF & iMF & TFMAP & PopRec & CLiMF & BRP\_MF & iMF & TFMAP  \\
\hline
P@5 & 0.0154 & 0.0154 & 0.0247 & \textbf{0.0393} & 0.0139 & 0.0294 &	0.0295 & 0.0420 & \textbf{0.0722} & 0.0289 \\
\hline
1call@5 & 0.0721 & 0.0725 &	0.1045 & \textbf{0.1582} & 0.0662 & 0.1307 &  0.1322 & 0.1608 & \textbf{0.2626} &	0.1295\\
\hline
NDCG@5 & 0.0179 & 0.0179 & 0.0265 &	\textbf{0.0430} & 0.0144 & 0.0335 &	0.0334 & 0.0439 & \textbf{0.0781} & 0.0324 \\
\hline
MAP@5 & 0.0428 & 0.0427 & 0.0566 & \textbf{0.0901} &	0.0325 & 0.0764 & 0.0764 & 0.0867 &	\textbf{0.1522} & 0.0738\\
\hline
MRR &  0.0597 &	0.0589 & 0.0775 & \textbf{0.1151} & 0.0490 & 0.1024 & 0.1013 & 0.1150 & \textbf{0.1864} &	0.0989\\
\hline
AUC & 0.8457 & 0.7213 & \textbf{0.8710} & 0.8703 &  0.8376 &  0.8460 & 0.7073 &	0.8631 & \textbf{0.8665} & 0.8354\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table}

\begin{table}[H]
\caption{Набор данных Movie Lens 1m}
\label{tab:2comp4}
%\begin{center}
\resizebox{0.7\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{n = 10} & \multicolumn{5}{|c|}{n = 5}\\
\hline
   & PopRec & CLiMF & BRP\_MF & iMF & TFMAP & PopRec & CLiMF & BRP\_MF & iMF & TFMAP  \\
\hline
P@5 & 0.1336 & 0.1157 &	0.2237 & \textbf{0.2600} & 0.0792 &  0.2265 & 0.212507 & 0.3345 & \textbf{0.3972} & 0.1405 \\
\hline
1call@5 & 0.4112 & 0.3692 &	0.6141 & \textbf{0.6520} & 0.2870 & 0.5779 & 0.5595 & 0.7531 & \textbf{0.8010} & 0.4420\\
\hline
NDCG@5 & 0.1439 & 0.1198 & 0.2400 &	\textbf{0.2799} & 0.0838 & 0.2387 &	0.2181 & 0.3501 & \textbf{0.4175} & 0.1504\\
\hline
MAP@5 & 0.2564 & 0.2091 & 0.3942 &	\textbf{0.4424} & 0.1603 &  0.3780 &  0.3399 & 0.5085 &	\textbf{0.5767} & 0.2689\\
\hline
MRR &  0.3780 &	0.3399 & 0.5085 & \textbf{0.5767} & 0.2689 & 0.4189 & 0.3856 & 0.5588 & \textbf{0.6255} & 0.3142\\
\hline
AUC & 0.8573 & 0.8489 &	\textbf{0.9244} & 0.9171 & 0.8491 &  0.8579 & 0.8523 & \textbf{0.9228} & 0.9157 &	0.8502\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table}

CLiMF и TFMAP показывают такое же качество, что и PopRec. 

BPR\_MF стабильно показывает более высокое качество, чем PopRec, а iMF  работает значительно лучше по всем метрикам, кроме AUC. 

Далее в работе будет показано, что несмотря на значительную разницу в качестве работы методов, при помощи ансамблирования можно добитьcя более лучшего результата.


\subsection{Составление линейного  ансамбля}


Пусть имеется множество базовых алгоритмов $b_i(x)$. Необходимо подобрать такие веса $\alpha_i$, чтобы линейная комбинация алгоритмов $\hat{b}(x) = \sum_i \alpha_i b_i(x)$ показывала лучший результат по какому-нибудь заданному функционалу. 

В нашем случае $b_i$ - методы ранжирования описанные ранее. Каждый метод возвращает ранжированный список предметов, который неудобно использовать в задаче ансамблирования. Удобнее использовать величину $f_{ui}$, которую можно интерпретировать как меру предпочтения. Обозначим  за $f_{ui}^m$ значение $f_{ui}$ $m$-ого базового метода.

Заметим, что для алгоритмов ранжирования  важно не само значение $f_{ui}$, а их порядок друг относительно друг. Поэтому диапазон значений этой величины у каждого алгоритма разный и зависит от функционала качества и регуляризатора. Поэтому, чтобы линейный комбинации были корректны,  необходимо нормировать значения $f_{ui}$ для каждого пользователя $u$. В результате $0 \leq f_{ui} \leq 1$. Далее будем считать, что все $f_{ui}$ нормированы.

  Рассмотрим несколько способов создание ансамблей:
 
\begin{itemize}
\item Простое голосование. 
\item Взвешенное голосование при помощи линейной регрессии.
\item Оптимальное взвешенное голосование
\end{itemize}
%Каждый факторизационный метод возвращает для пользователя $u$ множество значений $f_ui$ для всех $i$, которые можно интерпретировать как меру предпочтения пользователя $u$ предмета $i$.
Для экспериментов над ансаблями наборы данных были разбиты на 3 выборки: тренировочную, тестовую и валидационную. На тренировочной обучаются факторизационые методы, на валидационной настраиваются веса, а на тестовой вычисляется качество работы ансамбля. 

\subsubsection*{Простое голосование}
Один из простейших методов, который представляет из себя линейную комбинацию базовых методов с равными весами.
\begin{equation*}
 	\hat{b}(x)= \frac{1}{T}\sum_{m = 1} ^ T b_m(x)
\end{equation*}

В случае ранжирования данная выражение будет выглядеть следующим образом.

\begin{equation*}
	\hat{f}_{ui} = \frac{1}{T}\sum_{m = 1} ^ T f_{ui}^m
\end{equation*}
\subsubsection*{Взвешенное голосование при помощи линейной регрессии}

Линейная регрессия была одним из самых простых способов ансамблирования, которые были реализованы победителями конкурса Netflix.  Основная  проблема линейной регрессии и всех остальных методов агрегирования из этого конкурса в том, что они оптимизируют совершенно другой функционал. А именно RMSE. Но с другой стороны iMF тоже хорошо справляется с  задачей хоть и не оптимизирует на прямую метрики ранжирования.

Пусть у пользователя l предметов лежит в валидационной выборке. Они все релевантные. Далее случайным образом выберем 5l предметов, которые не лежат ни в валидационной, ни в тренировочной выборке, и объявим их нерелевантными. В итоге из этих предметов строим матрицу признаков $X$ и целевой вектор $y$. 

\begin{table}[H]
\label{tab:schemetable}
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
 \multicolumn{4}{|c|}{X} & \multicolumn{1}{|c|}{y}\\
\hline
  $f_{ui_1} ^ {m_1}$& $f_{ui_1} ^ {m_2}$ & $f_{ui_1} ^ {m_3}$& $f_{ui_1} ^ {m_4}$& $R_{ui_1}$ \\
\hline
$f_{ui_2} ^ {m_1}$& $f_{ui_2} ^ {m_2}$ & $f_{ui_2} ^ {m_3}$& $f_{ui_2} ^ {m_4}$& $R_{ui_2}$ \\
\hline
$f_{ui_3} ^ {m_1}$& $f_{ui_3} ^ {m_2}$ & $f_{ui_3} ^ {m_3}$& $f_{ui_3} ^ {m_4}$& $R_{ui_3}$ \\
\hline
$f_{ui_4} ^ {m_1}$& $f_{ui_4} ^ {m_2}$ & $f_{ui_4} ^ {m_3}$& $f_{ui_4} ^ {m_4}$& $R_{ui_2}$ \\
\hline
... & ... & ... &  ... & ... \\
\end{tabular}
\end{center}
\caption{Схематичное изображение признаковой матрицы}
\end{table} 

Далее обучаем  линейную регрессию на матрице признаков X и на целевом векторе y. В экспериментах была использована готовая реализация линейной регрессии из библиотеки scikit-learn\footnote{\url{http://scikit-learn.org/stable/}}.

\subsubsection*{Оптимальное взвешенное голосование} 
      Рассмотрим линейную комбинацию двух алгоритмов ранжирования  в следующем виде:
\begin{equation*}
	\hat{f}_{ui} = \alpha f_{ui}^{m_1} + (1 - \alpha) f_{ui} ^ {m_2} \textrm{\ , где $0 \leq \alpha \leq 1$} 
\end{equation*}


	Заметим, что все метрики ранжирования меняются только при изменении порядка предметов в ранжированном списке, а не от самого изменения $f_{ui}$. Поэтому число различных значений метрики не может быть больше конечного числа. На рис.\ref{pic:latexpic} видно, что изменения порядка происходит в точках пересечения линий. Их  не более чем $O(|U||I|^2)$. 

\begin{figure}[h]
\center{\includegraphics[width=0.4\linewidth]{latexpic}}
\caption{Две вертикальные линии обозначают размер величины f. Чем выше точка, тем больше величина. Невертикальные линии обозначают линейные комбинации величин f. Если $\alpha$ = 0, то линейная комбинация учитывает только Ranker $m_1$, если $\alpha = 1$, то  линейная комбинация учитывает только Ranker $m_2$}
\label{pic:latexpic}
\end{figure}
	
	Идея метода состоит в вычислении качества ансамбля при различных $\alpha$ на валидационной выборке в поисках оптимального параметра\cite{learningrank1,learningrank2}. Теоретически  можно перебрать все значения $\alpha$, при которых значение метрики различны. Но количество различных точек $\alpha$ слишком велико, поэтому было решено брать только малое подмножество точек. Далее было замечено, если брать $\alpha$ равномерно от 0 до 1, то результат получается такой же. В экспериментах был использован последний вариант.
	
	Обозначим за $b(x) = (b_i, b_j)$ ансамбль двух алгоритмов при помощи оптимального взвешенного голосования. 
	Обобщим оптимальное взвешенное голосование для 4 методов двумя способами:
	\begin{itemize}
	\item при помощи бустинга. $(((b_1, b_2), b_3), b_4)$
	\item при помощи построения дерева. $((b_1,b_2), (b_3, b_4))$
	\end{itemize}
	
\subsection{Сравнение  ансамблей}
Введем несколько обозначений.
\begin{itemize}
\item 
BSM(best single method) - лучшее значение метрики достигаемое одиночным методом.
\item 
SV(Simple Vote)  - простое голосование.
\item 
RV(Regression Vote) - взвешенное голосование при помощи линейной регрессии.
\item 
OVB(Optimal Vote Boosting) - оптимальное взвешенное голосование при помощи бустинга.
\item 
OVT(Optimal Vote Tree) - оптимальное взвешенное голосование при помощи построения дерева.
\end{itemize}

В качестве оптимизирующей метрики для OVB и OVT была использована мера качества NDCG.

Для сравнения качества методов проведем два эксперимента. 

\subsubsection{Первый эксперимент}
  
  В тренировочной выборке у каждого пользователя будет trainK предметов. В валидационной -- validK. Остальные предметы лежат в тестовой выборке. Алгоритмы обучаются на тренировочной выборке, а качество работы измеряется на тестовой выборке. Далее такой эксперимент повторяется maxiter раз. Конечным результатом является средняя величина качества работы по метрикам и алгоритмам. 

В таблицах \ref{tab:3comp1}, \ref{tab:3comp2}, \ref{tab:3comp3} и \ref{tab:3comp4} показано качество работы ансамблей на различных данных и параметрах эксперимента.


\begin{table}[H]
\caption{Набор данных Epinion}
\label{tab:3comp1}
%\begin{center}
\resizebox{0.8\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{trainK = 5, validk=5, maxiter = 5} & \multicolumn{5}{|c|}{trainK = 10, validk = 5, maxiter = 5}\\
\hline
  & BSM  & SV &  RV & OVB & OVT &BSM  & SV & RV & OVB & OVT \\
\hline
P@5 & 0.1811 & 0.1986 & 0.2033 & \textbf{0.2108} & 0.2095 & 0.2364 & 0.2120& 0.1935& \textbf{0.2438} & 0.2387 \\
\hline
1call@5 & 0.5334  & 0.5622 &0.5707 & \textbf{0.5852} & 0.5847 & 0.6004 & 0.5651&0.5243 & \textbf{0.6190}& 0.6177\\
\hline
NDCG@5 & 0.2028 & 0.2190 & \textbf{0.2230} & 0.2305 & 0.2291 & 0.2456&0.2271 & 0.2060 &\textbf{0.2564} & 0.2529\\
\hline
MAP@5 & 0.3590 & 0.3734 & 0.3784 & \textbf{0.3892}& 0.3872 & 0.3775& 0.3670& 0.3339 &0.3995 & 0.\textbf{4011}\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table} 




\begin{table}[H]
\caption{Набор данных Slashdot}
\label{tab:3comp2}
%\begin{center}
\resizebox{0.8\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{trainK = 5, validk=5, maxiter = 5} & \multicolumn{5}{|c|}{trainK = 10, validk = 5, maxiter = 5}\\
\hline
  & BSM  & SV &  RV & OVB & OVT &BSM  & SV & RV & OVB & OVT \\
\hline
P@5 &  0.1098 &0.1137 &\textbf{0.1155} & 0.1121 & 0.1127& 0.1272 &0.1137 & 0.1111 &\textbf{0.1333} & 0.1322 \\
\hline
1call@5 &0.3507 & 0.3631& \textbf{0.3729} & 0.3560 & 0.3646 & 0.3796 & 0.3565&0.3760  & 0.4017 &\textbf{0.4071} \\
\hline
NDCG@5 & 0.1192&0.1214 & \textbf{0.1225}& 0.1209 & 0.1212& 0.1340 & 0.1175&0.1250  &\textbf{0.1407} &0.1397 \\
\hline
MAP@5 & 0.2134&0.2143 & \textbf{0.2177} & 0.2147 &0.2166 & 0.2277 & 0.2073 &0.2207&  0.2410& \textbf{0.2419}\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table}



\begin{table}[H]
\caption{Набор данных MovieLens 100k}
\label{tab:3comp3}
%\begin{center}
\resizebox{0.8\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{trainK = 5, validk=5, maxiter = 5} & \multicolumn{5}{|c|}{trainK = 10, validk = 5, maxiter = 5}\\
\hline
  & BSM  & SV &  RV & OVB & OVT &BSM  & SV & RV & OVB & OVT \\
\hline
P@5 & 0.5142 &0.5243 &0.5124 &\textbf{0.5321} &0.5296 &0.4930 & 0.5298 & \textbf{0.5622} &0.5513 & 0.5573 \\
\hline
1call@5 & 0.9317 & 0.9272& 0.9280 &\textbf{0.9372} &0.9347 & 0.9143& 0.9346& \textbf{0.9346}& 0.9230& 0.9230\\
\hline
NDCG@5 &0.5202 & 0.5392&0.5118 & \textbf{0.5455} & 0.5416&0.5116 & 0.5424 & 0.5727 &0.5647 & \textbf{0.5754}\\
\hline
MAP@5 & 0.6616 & 0.6842 &0.6435 & \textbf{0.6918} & 0.6868 & 0.6708&0.6907 & 0.7060 &0.6979 & \textbf{0.7133}\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table}


\begin{table}[H]
\caption{Набор данных MovieLens 1m}
\label{tab:3comp4}
%\begin{center}
\resizebox{0.8\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{trainK = 5, validk=5, maxiter = 5} & \multicolumn{5}{|c|}{trainK = 10, validk = 5, maxiter = 5}\\
\hline
  & BSM  & SV &  RV & OVB & OVT &BSM  & SV & RV & OVB & OVT \\
\hline
P@5 & 0.4700 & 0.4957 &0.4947& \textbf{0.5104} &0.5028 & 0.5484& 0.5312& 0.4926&0.5709 & \textbf{0.5772}  \\
\hline
1call@5 & 0.8587 &0.8812 & 0.8835  &0.8942 &\textbf{0.8990}  & 0.9131& 0.8835& 0.8574& 0.9201&\textbf{0.9225} \\
\hline
NDCG@5 & 0.4832 & 0.5099& 0.5101&\textbf{0.5268} & 0.5183 & 0.5603 &0.5344 & 0.4990&0.5847 &\textbf{0.5909} \\
\hline
MAP@5 & 0.6442 & 0.6606& 0.6568& \textbf{0.6728}& 0.6684 & 0.6922& 0.6633& 0.6410& 0.7136&\textbf{0.7187} \\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table}


\subsubsection{Второй  эксперимент}
В тестовой выборке у каждого пользователя будет ptest\% выборки. В валидационной pvalid\% выборки. 
А в тренировочной все остальные предметы. Далее  эксперимент повторяется maxiter раз. Конечным результатом является средняя величина качества работы по метрикам и алгоритмам. 

В таблицах \ref{tab:4comp1}, \ref{tab:4comp2}, \ref{tab:4comp3} и \ref{tab:4comp4} показано качество работы ансамблей на различных данных и параметрах эксперимента.

\begin{table}[H]
\caption{Набор данных MovieLens 100k}
\label{tab:4comp1}
%\begin{center}
\resizebox{0.8\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{ptest = 10\%, pvalid=10\%, maxiter = 5} & \multicolumn{5}{|c|}{ptest = 20\%, valid = 10\%, maxiter = 5}\\
\hline
  & BSM  & SV &  RV & OVB & OVT &BSM  & SV & RV & OVB & OVT \\
\hline
P@5 & 0.2965 & 0.1602 &	0.2528 & \textbf{0.3069} & 0.3019 & 0.4451 &	0.2531 & 0.3831 & \textbf{0.4498} & 0.4464 \\
\hline
1call@5 & 0.7344 & 0.4950 & 0.6712 & \textbf{0.7580} & 0.7555 & 0.8706 & 0.6203 & 0.8039 &	\textbf{0.8784} & 0.8734\\
\hline
NDCG@5 &0.3201 & 0.1778 & 0.2783 & \textbf{0.3307} &	0.3257 & 0.4705 & 0.2738 & 0.4070 &	\textbf{0.4770} & 0.4752\\
\hline
MAP@5 & 0.5035 & 0.3239 & 0.4599 & \textbf{0.5185} & 0.5152 & 0.6480 & 0.4261 & 0.5763 &	0.6555 & \textbf{0.6562}\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table}


\begin{table}[H]
\caption{Набор данных Epinion}
\label{tab:4comp2}
%\begin{center}
\resizebox{0.8\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{ptest = 10\%, pvalid=10\%, maxiter = 5} & \multicolumn{5}{|c|}{ptest = 20\%, valid = 10\%, maxiter = 5}\\
\hline
  & BSM  & SV &  RV & OVB & OVT &BSM  & SV & RV & OVB & OVT \\
\hline
P@5 & 0.0716 & 0.0295 &	0.0534 & \textbf{0.0764} & 0.0760 & 0.1283 &	0.0550 & 0.1000 & 0.1328 & \textbf{0.1363} \\
\hline
1call@5 &0.2710 & 0.1303 & 0.2183 &	\textbf{0.2921} & 0.2908 & 0.4179 & 0.2242 &	0.3595 & 0.4372 & \textbf{0.4438}\\
\hline
NDCG@5 &0.0775  & 0.0334 & 0.0572 &	\textbf{0.0830} & 0.0822 &  0.1384 &	0.0615 & 0.1062 & 0.1425 &	\textbf{0.1468}\\
\hline
MAP@5 & 0.1561 & 0.0759 & 0.1193 & \textbf{0.1688} & 0.1672 & 0.2536 & 0.1316 & 0.2035 & 0.2607 & \textbf{0.2686}\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table}


\begin{table}[H]
\caption{Набор данных Slashdot}
\label{tab:4comp3}
%\begin{center}
\resizebox{0.8\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{ptest = 10\%, pvalid=10\%, maxiter = 5} & \multicolumn{5}{|c|}{ptest = 20\%, valid = 10\%, maxiter = 5}\\
\hline
  & BSM  & SV &  RV & OVB & OVT &BSM  & SV & RV & OVB & OVT \\
\hline
P@5 & 0.0431 & 0.0186 &	0.0291 & \textbf{0.0438} & 0.0436 &  0.0746 & 0.0362 & 0.0519 &	0.0757 & \textbf{0.0758}\\
\hline
1call@5 & 0.1644 & 0.0866 & 0.1272 & \textbf{0.1683} & 0.1671 & 0.2570 & 0.1577 & 0.2038 & 0.2631 & \textbf{0.2653} \\
\hline
NDCG@5 & 0.0473 & 0.0201 &	0.0312 & \textbf{0.0481} & \textbf{0.0481} & 0.0803 &	0.0397 & 0.0556 & 0.0819 & \textbf{0.0822}\\
\hline
MAP@5 & 0.0959 & 0.0455 & 0.0684 & 0.0976 & \textbf{0.0978} & 0.1506 & 0.0877 & 0.1140 & 0.1550 & \textbf{0.1562}\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table}

\begin{table}[H]
\caption{Набор данных Movie Lens 1m}
\label{tab:4comp4}
%\begin{center}
\resizebox{0.8\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{ptest = 10\%, pvalid=10\%, maxiter = 5} & \multicolumn{5}{|c|}{ptest = 20\%, valid = 10\%, maxiter = 5}\\
\hline
  & BSM  & SV &  RV & OVB & OVT &BSM  & SV & RV & OVB & OVT \\
\hline
P@5 & 0.2601 & 0.1065 &	0.2374 & 0.2628 & \textbf{0.2639} &  0.3936 & 0.1974 & 0.3616 &	\textbf{0.3983} & 0.3944\\
\hline
1call@5 & 0.6541 & 0.3424 & 0.6186 & 0.6566 & \textbf{0.6593} & 0.7985 & 0.5255 & 0.7714 & \textbf{0.8075} & 0.8066\\
\hline
NDCG@5 & 0.2795 & 0.1104 & 0.2476 &	0.2830 & \textbf{0.2836} & 0.4127 &	0.2007 & 0.3710 & \textbf{0.4192} & 0.4157\\
\hline
MAP@5 & 0.4384& 0.1936 & 0.3859 & 0.4440 & \textbf{0.4438} & 0.5729 & 0.3127 & 0.5166 & \textbf{0.5839} & 0.5822\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table}


По результатам эксперимента видно, что SV работает хорошо, если качество методов примерно равны. Если один из методов работает намного лучше другого, то он хуже BSM. Аналогичная ситуация с RV.

OVB и OVT стабильно показывают хорошее качество во всех поставленных ситуациях.

\subsubsection{Сравнение разных метрик для оптимальных комбинаций}
Одним из параметров OVB и OVT является оптимизирующий функционал. Исследуем какой функционал лучше выбирать в качестве оптимизирующего.

В таблицах \ref{tab:4comp1}, \ref{tab:4comp2}, \ref{tab:4comp3} и \ref{tab:4comp4} показано качество работы ансамблей на различных данных и параметрах второго эксперимента. В качестве ансамбля был взят OVT. 


\begin{table}[H]
\caption{Набор данных Movie Lens 100k}
\label{tab:4comp1}
%\begin{center}
\resizebox{0.7\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{test = 0.1, valid=0.1, maxiter = 5} & \multicolumn{5}{|c|}{test = 0.2, valid = 0.1, maxiter = 5}\\
\hline
  & BSM	& P@5 & 1call@5	& NDCG@5 & MAP@5 & BSM	& P@5 & 1call@5	& NDCG@5 & MAP@5\\
\hline
P@5 & 0.2866 & 0.3024 &	0.3007 & 0.2987 & \textbf{0.3037} &  0.4466 & 0.4522 & 0.4476 & 0.4466 &	\textbf{0.4526} \\
\hline
1call@5 & 0.7406 &  0.7717 & 0.7729 & 0.7630 & \textbf{0.7667} & 0.8672 & 0.8707 & 0.8660 & 0.8672 & \textbf{0.8709}\\
\hline
NDCG@5 &0.3163 & 0.3292 & 0.3266 &	0.3281 & \textbf{0.3303} &  0.4721 &0.4790 & 0.4748 & 0.4721 &	\textbf{0.4794}\\
\hline
MAP@5 &0.5156 & 0.5242 & 0.5269 & \textbf{0.5271} & 0.5223 & 0.6448 & 0.6530 & \textbf{0.6483} &  0.6448 & 0.6530 \\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table}

\begin{table}[H]
\caption{Набор данных Epinion}
\label{tab:4comp2}
%\begin{center}
\resizebox{0.7\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{test = 0.1, valid=0.1, maxiter = 5} & \multicolumn{5}{|c|}{test = 0.2, valid = 0.1, maxiter = 5}\\
\hline
  & BSM	& P@5 & 1call@5	& NDCG@5 & MAP@5 & BSM	& P@5 & 1call@5	& NDCG@5 & MAP@5\\
\hline
P@5 & 0.0766 & 0.0784 &	0.0753 & \textbf{0.0779} & 0.0786 &  0.1264 & 0.1307 & 0.1310  & \textbf{0.1321} & 0.1317\\
\hline
1call@5 & 0.2854 & 0.2935 & 0.2871 & \textbf{0.2942} & 0.2935 & 0.4152 & 0.4242 & 0.4241 & 0.4330 & \textbf{0.4338} \\
\hline
NDCG@5 & 0.0836 & 0.0850 &	0.0825 & 0.0853 & \textbf{0.0855} & 0.1351 &	0.1386 & 0.1392 & 0.1400 &	\textbf{0.1409}\\
\hline
MAP@5 &0.1665 & 0.1704 & 0.1682 & \textbf{0.1725} & 0.1710 &0.2469 & 0.2501 & 0.2500 & 0.2555 & \textbf{0.2559}\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table}



\begin{table}[H]
\caption{Набор данных Slashdot}
\label{tab:4comp3}
%\begin{center}
\resizebox{0.7\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{test = 0.1, valid=0.1, maxiter = 5} & \multicolumn{5}{|c|}{test = 0.2, valid = 0.1, maxiter = 5}\\
\hline
  & BSM	& P@5 & 1call@5	& NDCG@5 & MAP@5 & BSM	& P@5 & 1call@5	& NDCG@5 & MAP@5\\
\hline
P@5 & 	0.0408 & \textbf{0.0421} & \textbf{0.0421} & \textbf{0.0421} & \textbf{0.0421} & 0.0732 & \textbf{0.0757} & \textbf{0.0757} & \textbf{0.0757} & \textbf{0.0757}\\
\hline
1call@5 & 0.1573 & \textbf{0.1637} & \textbf{0.1637} & \textbf{0.1637} & \textbf{0.1637} & 0.2484 & \textbf{0.2587} & \textbf{0.2587} & \textbf{0.2587} & \textbf{0.2587}\\
\hline
NDCG@5 & 0.0450 & \textbf{0.0465} & \textbf{0.0465} & \textbf{0.0465} & \textbf{0.0465} & 0.0790 & \textbf{0.0820} & \textbf{0.0820} &	\textbf{0.0820} & \textbf{0.0820}\\
\hline
MAP@5 &0.0921 & \textbf{0.0955} & \textbf{0.0955} & \textbf{0.0955} & \textbf{0.0955} & 0.1476 & \textbf{0.1550} & \textbf{0.1550} & \textbf{0.1550} & \textbf{0.1550} \\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table}


\begin{table}[H]
\caption{Набор данных Movie Lens 1m}
\label{tab:4comp4}
%\begin{center}
\resizebox{0.7\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{test = 0.1, valid=0.1, maxiter = 5} & \multicolumn{5}{|c|}{test = 0.2, valid = 0.1, maxiter = 5}\\
\hline
  & BSM	& P@5 & 1call@5	& NDCG@5 & MAP@5 & BSM	& P@5 & 1call@5	& NDCG@5 & MAP@5\\
\hline
P@5 & 0.2570 & \textbf{0.2614} & 0.2604 & 0.2610 & 0.2610 & 0.3981 & \textbf{0.4020}& \textbf{0.4020} & 0.4012 & \textbf{0.4020}\\
\hline
1call@5 & 0.6482 & 0.6581 & \textbf{0.6588} & 0.6570 & 0.6570 & 0.7985 & \textbf{0.8122} & \textbf{0.8122} & 0.8062 & \textbf{0.8122}\\
\hline
NDCG@5 & 0.2762 & \textbf{0.2804} & 0.2794 & 0.2802 & 0.2802 & 0.4178 & 0.4220 & 0.4220 & \textbf{0.4221} & 0.4220\\
\hline
MAP@5 & 0.4362 & 0.4424 & 0.4422 & \textbf{0.4426} & \textbf{0.4426} & 0.5760 & 0.5819 & 0.5819 & \textbf{0.5834} & 0.5819\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table}

Никакой значительной зависимости качества ансабля от выбора оптимизирующего функционала замечено не было. Более того, на наборе данных Slashdot линейные коэффициенты настроились одинаково на всех метриках.

Из-этого можно сделать вывод, что выбор функционала не играет существенной роли. 

\section{Заключение}
В ходе работы были получены следующие результаты.

\begin{enumerate}

\item Составлен обзор основных факторизационных методов для задачи ранжирования для набора данных с двоичной релевантностью.

\item Предложен метод ансамблирования, который стабильной улучшает качество работы ранжирования.

\item Реализованы факторизационные методы  и эксперименты на языке python и c++.
\end{enumerate}




\newpage

	\begin{thebibliography}{00} % библиография
	\addcontentsline{toc}{section}{Список литературы}
    	\bibitem{climf}
    	
    	Yue Shi, Alexandros Karatzoglou, Linas Baltrunas.
    	
CLiMF: learning to maximize reciprocal rank with collaborative less-is-more filtering. 	
    	
    RecSys '12 the sixth ACM conference on Recommender systems, 2012.    	
    	
         \bibitem{bprmp}
         
	     Steffen Rendle, Christoph Freudenthaler, Zeno Gantner.    
         
         BPR: Bayesian Personalized Ranking from Implicit Feedback.
         
         UAI '09 Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, 2009
         
		\bibitem{tfmap}
		
		Yue Shia,Alexandros Karatzogloub, Linas Baltrunas.
		
TFMAP: Optimizing MAP for Top-N Context-aware Recommendation.		
		
		35th international ACM SIGIR conference on Research and development in Information Retrieval, 2012
		
	\bibitem{imf}
	Yifan Hu, Yehuda Koren, Chris Volinsky.
	
	Collaborative Filtering for Implicit Feedback Datasets.
	
	8th IEEE International Conference on Data Mining, 2008.
	
	
	\bibitem{matrixfactorization}
	Y. Koren, R. Bell, C. Volinsky.	
	
	Matrix Factorization Techniques for Recommender Systems.
	
	Computer IEEE, 2009
	\bibitem{netflix}
	Yehuda Koren
	
	The BellKor Solution to the Netflix Grand Prize. 
	
	2009

	\bibitem{reasonbadwork}
	
    Paolo Cremonesi, Yehuda Koren, Roberto Turrin	
	
	Performance of Recommender Algorithms on Top-N Recommendation Tasks
	
	RecSys '10 Proceedings of the fourth ACM conference on Recommender systems. 2010
	
	\bibitem{learningrank1}
	
	Christopher J. C. Burges, Krysta M. Svore, Paul N. Bennett
		
	Learning to Rank Using an Ensemble of Lambda-Gradient Models.
	
	JMLR: Workshop and Conference Proceedings 14. 2011
		
	\bibitem{learningrank2}
	
	Qiang Wu, Christopher J. C. Burges, Krysta M. Svore	
	
	Adapting Boosting for Information Retrieval Measures.
	
	Information Retrieval, 2010 - Springer. 2010
	
\end{thebibliography}
\end{document}
