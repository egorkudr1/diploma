\documentclass[a4paper,12pt]{article} 
\usepackage[T1,T2A]{fontenc} 
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amssymb,amsfonts,amsmath,mathtext,cite,enumerate,float}
\usepackage[hidelinks]{hyperref}
\usepackage{graphicx}
\usepackage{adjustbox}
\usepackage {indentfirst}
\usepackage{amsmath}
\usepackage{indentfirst}
\usepackage{bbm}
%\usepackage[linesnumbered,boxed]{algorithm2e}

\usepackage{geometry} % Меняем поля страницы
\geometry{left=2cm}% левое поле
\geometry{right=2cm}% правое поле
\geometry{top=1cm}% верхнее поле
\geometry{bottom=2cm}% нижнее поле

\newcommand{\argmin}{\operatornamewithlimits{argmin}}
%\newcommand{\min}{\operatornamewithlimits{min}}
%для русского псевдокода
%\SetKwInput{KwData}{Входные данные}
%\SetKwInput{KwResult}{Результат}
%\SetKwInput{KwIn}{Входные данные}
%\SetKwInput{KwOut}{Выходные данные}
%\SetKwIF{If}{ElseIf}{Else}{если}{тогда}{иначе\ если}{иначе}{конец\ условия}
%\SetKwFor{While}{до\ тех\ пор,\ пока}{выполнять}{конец\ цикла}
%\SetKw{KwTo}{от}
%\SetKw{KwRet}{возвратить}
%\SetKw{Return}{возвратить}
%\SetKwBlock{Begin}{начало\ блока}{конец\ блока}
%\SetKwSwitch{Switch}{Case}{Other}{Проверить\ значение}{и\ выполнить}{вариант}{в\ противном\ случае}{конец\ варианта}{конец\ проверки\ значений}
%\SetKwFor{For}{цикл}{выполнять}{конец\ цикла}
%\SetKwFor{ForEach}{для\ каждого}{выполнять}{конец\ цикла}
%\SetKwRepeat{Repeat}{повторять}{до\ тех\ пор,\ пока}
%\SetAlgorithmName{Алгоритм}{алгоритм}{Список алгоритмов}

\usepackage{algorithm}
\usepackage{algpseudocode}

\renewcommand{\listalgorithmname}{Список алгоритмов}
\floatname{algorithm}{Алгоритм}

\algrenewcommand\algorithmicwhile{\textbf{До тех пока}}
\algrenewcommand\algorithmicdo{\textbf{выполнять}}
\algrenewcommand\algorithmicrepeat{\textbf{Повторять}}
\algrenewcommand\algorithmicuntil{\textbf{Пока}}
\algrenewcommand\algorithmicend{\textbf{Конец}}
\algrenewcommand\algorithmicif{\textbf{Если}}
\algrenewcommand\algorithmicelse{\textbf{иначе}}
\algrenewcommand\algorithmicthen{\textbf{тогда}}
\algrenewcommand\algorithmicfor{\textbf{Цикл}}
\algrenewcommand\algorithmicforall{\textbf{Выполнить для всех}}
\algrenewcommand\algorithmicfunction{\textbf{Функция}}
\algrenewcommand\algorithmicprocedure{\textbf{Процедура}}
\algrenewcommand\algorithmicloop{\textbf{Зациклить}}
\algrenewcommand\algorithmicrequire{\textbf{Вход:}}
\algrenewcommand\algorithmicensure{\textbf{Выход:}}
\algrenewcommand\algorithmicreturn{\textbf{Выход:}}
\algrenewtext{EndWhile}{\textbf{Конец цикла}}
\algrenewtext{EndLoop}{\textbf{Конец зацикливания}}
\algrenewtext{EndFor}{\textbf{Конец цикла}}
\algrenewtext{EndFunction}{\textbf{Конец функции}}
\algrenewtext{EndProcedure}{\textbf{Конец процедуры}}
\algrenewtext{EndIf}{\textbf{Конец условия}}
\algrenewtext{EndFor}{\textbf{Конец цикла}}
\algrenewtext{BeginAlgorithm}{\textbf{Начало алгоритма}}
\algrenewtext{EndAlgorithm}{\textbf{Конец алгоритма}}
\algrenewtext{BeginBlock}{\textbf{Начало блока. }}
\algrenewtext{EndBlock}{\textbf{Конец блока}}
\algrenewtext{ElsIf}{\textbf{иначе если }}




\begin{document}
\begin{titlepage}
\begin{center}

    \bigskip
    \includegraphics[width=50mm]{titul_cartoon}

    \bigskip
    Московский государственный университет имени М.\,В.~Ломоносова
    Факультет Вычислительной математики и кибернетики\\
    Кафедра Математических методов прогнозирования\\[30mm]

    \textsf{\large
      ВЫПУСКНАЯ КВАЛИФИКАЦИОННАЯ РАБОТА \\[10mm]
      \textbf{
        Построение ансамбля алгоритмов рекомендаций
      }
    }\\[30mm]

    \begin{flushright}
      \parbox{0.5\textwidth}{
        \raggedleft
        \textbf{Выполнил:}\\
        студент 417 группы\\
        Кудрявцев Георгий Алексеевич\\[5mm]
        \textbf{Научный руководитель:}\\
        д.ф-м.н., профессор\\
        Дьяконов Александр Геннадьевич
      }
    \end{flushright}

    \vspace{\fill}
    Москва, 2015
\end{center}
\end{titlepage}
\thispagestyle{empty} % не нумеровать первую страницу
\newpage

\tableofcontents % сгенерировать оглавление
\newpage
\section{Введение}
%Что такое и зачем рекомендательные системы.
%Что такое Коллаборативная фильтрация
%Вида методов колллаборативной фильтрации
%Что такое явный и неявный отклик.
%Наша задача + объяснение ее актуальности

С ростом популярности электронной коммерции, возникла задача помощи пользователям в поиске товаров, которые им понравятся. Одними из инструментов, используемые для решения этой проблемы, являются рекомендательные системы. 

Коллаборативная фильтрация является одним из методов построения рекомендательных систем. Она использует известные оценки или предпочтения пользователей для построения рекомендации пользователям, чьи оценки и предпочтения неизвестны. Идея данного метода состоит в предположении того, что пользователи, имеющие похожие предпочтения в прошлом, будут иметь похожие предпочтения в будущем.



Существует три различных подхода в коллаборативной фильтрации.

Первый подход называется Memory-based. Его идея заключается в вычислении сходства между пользователями или предметами. Соответственно, похожие предметы или пользователи должны иметь похожие оценки или предпочтения.

Второй подход называется Model-based. Его идея заключается в создание моделей при помощи интеллектуального анализа данных и машинного обучения. Модель обучается на реальных данных, например, на истории покупок интернет-магазина, а далее выдает рекомендации для пользователей, чьи предпочтения неизвестны. 

Третий подход -- Hybrid. Его идея заключается в использовании первого и второго подхода, компенсируя недостатки обоих. 


В данной работе будет рассматриваться второй подход.

Также следует упомянуть о таком важном понятии как обратная связь(feedback). Обратной связью некоторого пользователя на предмет называют некоторое событие, по которому можно судить о предпочтении автора. 
Например, это может быть оценка фильма по десятибалльной шкале. Либо клик на описание товара в интернет-магазине.

В коллаборативаной фильтрации выделяют два типа обратной связи: с явным откликом(explicit feedback) и неявным откликом(implicit feedback).

 В первом случае пользователь осознано оценивает предмет и производит соответствующий отклик. Например, пользователь оценивает работу интернет-магазина по пятибалльной шкале.

Неявный отклик  означает лишь, что между пользователем и предметом произошло взаимодействие. Например, покупатель зашел на страницу с описанием товара, либо несколько раз посмотрел  видеоролик. Как видно, из этого отклика нельзя выяснить имеется ли у пользователя положительное или отрицательное предпочтение к предмету, и есть ли оно вообще.

В данной работе будет рассмотрен случай, в котором набор данных состоит только из неявного отклика, причем он будет в бинарном виде, то есть '1' - будет означать, что пользователь имел взаимодействие с предметом и '0', если такого взаимодействия не было.  Такая ситуация возможна в некоторых случаях. Например, дружба между пользователями в социальной сети или история встреч на сайте знакомств. Далее будем считать, что неявный отклик показывает положительное предпочтение пользователя к предмету.


В качестве моделей будет рассмотрен класс факторизационных методов. Их основная идея лежит в представлении предпочтения пользователя к предмету  в виде скалярного произведения их латентных векторов\cite{matrixfactorization}.  Данные методы хорошо себя показали в известном конкурсе Netflix Prize\cite{netflix}.

Также в решении победителей не малую роль сыграл ансамбль алгоритмов. Поэтому в данной работе было  решено исследовать, как можно улучшить качество современных факторизационных методов в задаче ранжирования при помощи  построения ансамблей. 

\section{Цель работы}
Целью работы является изучение и сравнение существующий факторизационных методов ранжирования, а также создание новых, более эффективных при помощи построения ансамблей. 


Данная работа может быть разделена на несколько частей.
\begin{enumerate}
\item Ввод необходимых понятий и обозначений.
\item Обзор современных методов ранжирования
\item Построение различных ансамблей методов ранжирования.
\item Тестирование и сравнение методов и ансамблей на реальных данных.
\end{enumerate}


\section{Обозначения}

Набор данных R представлен в виде матрицы  размером $|U| \times |I|$, где $U$ - множество пользователей, и $I$ - множество предметов. В дальнейшем обозначим $M = |U| $ и $N = |I|$

Если между пользователем $u$ и предметов $i$ произошел неявный отклик, то $R_{ui}=1$. В противном случае $R_{ui} = 0$. Будем считать, что предмет $i$ релевантен пользователю $u$, если $R_{ui}$


Обозначим за $rank(u, i)$ номер позиции предмета i в упорядоченном списке, который был получен при помощи метода ранжирования, для пользователя $u$.   

Введем функцию $rel(u, k)$ такую что, $rel(u, k)$ = 1, если предмет, стоящий на $k$ позиции в упорядоченном списке предметов для пользователя $u$, релевантен. В противном случае $rel(u, k)$ = 0.  


Пусть  

$P$ - множество профилей пользователей, 

$Q$ - множество профилей предметов,

$P_u$ - профиль(латентный вектор) пользователя $u$ и

$Q_i$ - профиль(латентный вектор) предмета $i$.

Прогноз $f_{ui}$ предпочтения пользователя $u$ предмета $i$ будет представлен в виде скалярного произведения латентных векторов $P_u$ и $Q_i$, т.е. $f_{ui} = \langle P_u, Q_i \rangle$

Также в дальнейшем будет часто использоваться сигмоида. Обозначим ее за $\sigma(x) = \frac{1}{1 + e^{-x}}$. 
%\section{Постановка задачи}
%
%Дана матрица описаний транзакций R. По ней нужно построить метод ранжирования, который будет для каждого пользователя $u$ выдавать список предметов в порядке релевантности. Будем считать, что предмет $i$ релевантен пользователю $u$, если $R_{ui} =1$.

\section{Критерии качества}
В задаче ранжирования не существует однозначно правильного функционала качества. Поэтому было решено использовать сразу несколько.

\subsection{$P@n$}
	Определим эту метрику для одного пользователя.
	\begin{equation*}
		P@n(u) = \frac{1}{N}\sum_{k = 1}^n rel(u, k)
	\end{equation*}
	
	Теперь для всех пользователей.
	\begin{equation*}
		P@n = \frac{1}{M}\sum_{u = 1}^M P@n(u)
	\end{equation*}
	$P@n$ показывает среднюю долю релевантных объектов по всем пользователям.  Недостатком этой метрики является то, что она не учитывает порядок предметов. Например,  если пользователь получил только один релевантный предмет, то для этой метрики не важно, был ли он в начале списка или в конце. 
\subsection{$1call@n$}
	Определим эту метрику для одного пользователя.
	\begin{equation*}
		1call@n(u) = [\sum_{k = 1}^n rel(u, k) > 0]
	\end{equation*}
	
	Теперь для всех пользователей.
	\begin{equation*}
		P@n = \frac{1}{M}\sum_{u = 1}^M 1call@n(u)
	\end{equation*}
	$1call@n$ показывает долю запросов по всем пользователям, у которых был хотя бы один релевантный предмет. Метрика не учитывает  ни порядок, ни количество релевантных предметов. 
\subsection{$MRR$}
	MRR -- Mean Reciprocal Rank
	
	Пусть $firstrank(u)$  - номер позиции первого релевантного предмета в ранжированном списке для пользователя $u$. Номер позиции в списке начинается с 1.
	\begin{equation*}
		MRR = \frac{1}{M}\sum^{M}_{u=1}\frac{1}{firstrank(u)}	
	\end{equation*}
	
	Эта метрика используется, если рекомендательной системе важнее подать пользователю один релевантый предмет в начало списка. 

	 
\subsection{$NDCG@n$}
	NDCG -- Normalized Discounted Cumulative Gain
	
	\begin{equation*}
	\begin{split}
	 & G(u, k) = 2^{rel(u, k)} - 1 \\
	 & D(k) = \frac{1}{log_2(k + 1)} \\
	 & DCG@n(u) = \sum_{k=1}^n G(u, k) D(k) \\
	 & NDCG@n(u) = \frac{DCG@n(u)}{max DCG@n}
	\end{split}			
	\end{equation*}
	
	Эта метрика является популярной в информационном поиске. Она учитывает и порядок, и количество релевантных предметов. Также большим плюсом является то, что $NDCG$ работает в случае различных уровней релевантностей.
	
\subsection{$MAP$}
	MAP -- 	Mean Average Precision
	
	
	\begin{equation*}
	\begin{split}
	 & AP@n(u) = \frac{1}{n}\sum_{k=1}^n rel(u, k) P@k(u)  \\
	 & MAP@n = \frac{1}{M}\sum_{k=1}^M AP@n(u) \\
	\end{split}			
	\end{equation*}
	
	Аналогично предыдущей метрике, $MAP$ является достаточно популярной, учитывает и порядок, и количество релевантных предметов.
	
	
%\subsection{$AUC$}

\section{Существующие методы}
В ходе работы были рассмотрены факторизационные методы ранжирования. Их основная идея заключается в представлении пользователей и предметов в виде векторов латентных векторов $P_u$ и $Q_i$. Величина $f_{ui} = \langle P_u, Q_i\rangle$  показывает заинтересованность пользователя $u$ в предмете  $i$. Соответственно, по величине $f_{ui}$ можно ранжировать предметы для конкретного пользователя.
	
Далее приведен список факторизационных методов с их кратким описанием.  
\begin{enumerate}
\item \textbf{CLiMF} --
  Факторизационный метод, который оптимизирует сглаженную версию метрики MRR.\cite{climf}
  	
\item \textbf{MPR\_MF} -- 
  Факторизационный метод, который оптимизирует AUC.\cite{bprmp}
  
\item \textbf{TFMAP} --
   Факторизационный метод, который оптимизирует сглаженную метрику MAP.\cite{tfmap}

\item \textbf{iMF} --
	Факторизационный метод, который оптимизирует взвешенную квадратичную ошибку.\cite{imf} 

\item \textbf{PopRec} --
    Простой метод, который ранжирует предметы по убыванию количества пользователей, для которых данный предмет является релевантным. В результате метод выдает для каждого пользователя один  и тот же ответ.
\end{enumerate}

\subsection{CLiMF}
Данный метод использует в качестве функционала качества MRR. Заметим, что MRR можно переписать в другом виде.
\begin{equation*}
 MRR =\frac{1}{M}\sum_{u=1}^M \sum_{i=1}^N \frac{R_{ui}}{rank(u,i)}\prod_{k=1}^N(1 - R_{uk}[rank(u,k) - rank(u, i)])
\end{equation*}
 Но  MRR не является гладкой функцией, поэтому авторы метода решили оптимизировать сглаженную версию этой метрики. В качестве регуляризатора был взят L2-регуляризатор. В итоге получаем следующий функционал качества.

\begin{equation*}
	F(P, Q) = \sum_{u=1}^M \sum_{i=1}^N [R_{ui}(\ln(\sigma(f_{ui})) + \sum_{k=1}^N \ln(1 - R_{uk}\sigma(f_{uk} < f_{ui})))] - \frac{\lambda}{2}({||U||}^2 + {||V||}^2 ) 
	\end{equation*}	

Далее этот функционал оптимизируется при помощи стохастического градиентного спуска.

\begin{algorithm}[h]
\caption{обучение метода CLiMF}
\begin{algorithmic}[1]
\Require {набор данных R, параметр регуляризации $\lambda$, скорость обучение $\gamma$, 
максимальное число итерации maxiter}
\Ensure {обученные латентные векторы P, Q}
\For{i = 1 .. M}
\State $N_u = \{i | R_{ui} > 0, 1 \leq i \leq N\}$
\EndFor

инициализируем $U^{(0)}$ и $V^{(0)}$ случайными значениями. t = 0.
\Repeat {} 
\For {i = 1 .. N}
		\State $P_u^{(t+1)} = P_u^{(t)} + \gamma \frac{\partial F}{\partial P_u^{(t)}}$
			\For {$i \in N_u$}
				\State 	$Q_i^{(t+1)} = Q_i^{(t)} + \gamma \frac{\partial F}{\partial 	  																						Q_i^{(t)}}$		
			\EndFor	
	\EndFor 
\Until{$t \leq itermax$}

\end{algorithmic}
\label{alg:climf}
\end{algorithm}
\newpage
\subsection{BRP\_MF}  	

Авторы данного метода применили байесовкий подход к решению задачи ранжирования. Для каждого пользователя $u$  предметы были разбиты на 3 класса: релевантные и нерелевантные предметы, а также предметы с неизвестной релевантностью. Собственно, для последнего класса и нужно было строить ранжирование. 



Пусть $\theta$ - параметр метода. В нашем случае это $P$ и $Q$.  $I_u^+$ -- множество релевантных предметов пользователя u. $I_u^-$ -- множество нерелевантных предметов пользователя u.  $>_u$ - это ранжированный список предметов для пользователя u. Требуется максимизировать вероятность $p(\theta|>_u)$.
\begin{equation*}
\begin{split}
	& p(\theta| >_u) \propto p(>_u| \theta)p(\theta) \\
	& p(>_u| \theta) = \prod_{i, j: \ i \in I_u^+, j \in I_u^-}p(i >_u j| \theta)\\
	& p(\theta) \sim N(0, \lambda I) \\
	& p(i >_u j| \theta) = \sigma(f_{ui} - f_{uj}) 
\end{split}
\end{equation*}

В итоге имеем следующий функционал качества. 
\begin{equation*}
F(P, Q) = \ln(p(\theta| >_u)) = \ln(p(>_u|\theta)p(\theta)) = \sum_{u,i,j: u \in U\ i \in I_u^+\ j \in I_u^-}\ln(\sigma(f_{ui} - f_{uj})) - \lambda {||\theta||} ^ 2
\end{equation*}


Нормальное априорное распределение задает L2-регуляризацию, а сигмоида позволяет легко высчитывать производные для данного функционала. Авторами  было показано, что данный алгоритм оптимизирует AUC.

\begin{algorithm}[h]
\caption{обучение метода BRP\_MP}
\begin{algorithmic}[1]
\Require {набор данных R, параметр регуляризации $\lambda$, скорость обучение $\gamma$, 
максимальное число итерации maxiter}
\Ensure {обученные латентные векторы P, Q}
\State {Инициализируем $\theta$ случайными значениями, t = 0}
\Repeat {} 
	\State {берем случайную тройку $(u, i,j)$, где $u \in U, i \in I_u^+, j \in I_u^-$} 
	\State {$\theta = \theta + \alpha \big( \frac{1}{1 + e ^{(f_{ui} - f_{uj})}}  
	\frac{\partial}{\partial \theta} (f_{ui} - f_{uj}) + \lambda \theta \big)$} 
	\State {t = t + 1}
\Until{$t \leq itermax$}

\end{algorithmic}
\label{alg:climf}
\end{algorithm}

\newpage
\subsection{iMF}
За основу iMF был взят оригинальный SVD, функционал качества которого выглядит следующим образом.

\begin{equation*}
F(P, Q) = \sum_{R_{ui} - \textnormal{известно}} (R_{ui} - f_{ui})^2 + \lambda ({||P||} ^ 2 + {||Q||}^2)
\end{equation*}

Недостаток SVD заключается в том, что он показывает плохое качество ранжирования в поставленной задаче.
Чтобы преодолеть данную проблему, авторы метода поменяли функционал качества на следующий.

\begin{equation*}
\begin{split}
& F(P, Q) = \sum_{u, i} c_{ui}(g_{ui} - f_{ui})^2 + \lambda ({||P||} ^ 2 + {||Q||}^2) \\
& g_{ui} =  \begin{cases} 
   0  &\mbox{если } R_{ui} = 0 \\ 
   1 & \mbox{если } R_{ui} > 1 
\end{cases} \\
& c_{ui} = 1 + \alpha R_{ui}
\end{split}
\end{equation*}

Переменная $g_{ui}$ отвечает за неявный отклик между пользователем $u$ и предметом $i$. Т.е. iMF пытается определить не уровень предпочтения пользователя, а неявный отклик. Хотя в нашем случае это одно и тоже. 

Переменная $c_{ui}$ является весом каждого квадратного слагаемого. Чем больше предпочтение, тем больше вес. 

Метод обучается при помощи ALS.


%
%Переменная g_{ui} отвечает за неявный отклик. Будем делать прогноз не на $R_{ui}$, а на $g_{ui}$. Хотя в нашем случае это одно  и то же.  Также заметим, что намного 

\subsection{TFMAP}
Данный метод использует в качестве функционала качества MAP. Заметим, что MAP можно переписать в следующем виде. 
\begin{equation*}
 MAP = \frac{1}{M}\sum_{u=1}^M\frac{\sum_{i=1}^N \frac{R_{ui}}{rank(u, i)} \sum_{j=1}^N R_{uj} 
 [rank(u,j) \leq rank(u, i)]}{\sum_{i=1}^N R_{ui}} 
\end{equation*} 
 
 Далее проводятся рассуждения аналогичные CLiMF. Метрика TFMAP  не является гладкой, следовательно, будем оптимизировать приближенную гладкую версию это метрики. Также добавим L2-регуляризатор.
 
 В итоге получаем  следующую формулу.
 \begin{equation*}
 \begin{split}
 & F(P, Q) = \sum_{u=1}^M \frac{1}{\sum_{i=1}^N R_{ui}} \sum_{i=1}^N R_{ui} \sigma(f_{ij}) \times \sum_{j=1}^N R_{mj} \sigma(f_{uj} - f_{ui}) - \frac{1}{2}\lambda({||P||}^2 + {||Q||}^2)
 \end{split}
 \end{equation*}

Далее возникает проблема подсчета частной производной по $Q_i$. Она вычисляется при помощи следующей формулы. 

\begin{equation*}
 \frac{\partial F}{\partial Q_i} = \sum_{u=1}^M\frac{R_{ui} P_u}{\sum_{i=1}^N R_{ui}}\sum_{j=1}^N \Big(\sigma^{\prime}( f_{ui})\sigma(f_{uj} - f_{ui}) + (\sigma(f_{uj}) - \sigma(f_{ui}))\sigma^{\prime}(f_{uj} - f_{ui}) \Big )  R_{ui} - \lambda Q_i
\end{equation*}

Сложность вычисления этого выражения -- $O(KN|R|)$, где $K$ - размерность латентных векторов, $|R|$ -  количество взаимодействий пользователей с предметами. На практике подсчет такой производной несет большие вычислительные затраты. Для ускорения вычисления выражения авторы заменили $\sum_{i=1}^N$ на $\sum_{i \in B_{u}}$, где $B_{u}$ - множество предметов специального вида. Далее приведен алгоритм построения этого множества.

\begin{algorithm}[h]
\caption{построение множества $B_{u}$}
\begin{algorithmic}[1]
\Require {$Q_i$ и $f_{ui}$ для всех $i$,  размер выборки $n$, $P_u$}
\Ensure {$B_u$}
\State {$B_u = \emptyset$}
\State $B_u = B_u \cup \{i | R_{ui} = 1 \}$
\State $n_u = |B_u|$
\State $p = \min_{i \in B_u} f_{ui}$
\State $S  = \{i |R_{ui} = 0 \} \cap \{i| f_{ui} > p \}$
\State Случайно выбираем подмножество $L \subset S$ размера n.
\State Отсортируем предметы $i \in L$ по убыванию $f_{ui}$
\State Выбираем первые $n_u$ предметов из полученного списка. Обозначим это множество предметов за $B^{-}$
\State $B_u = B_u \cup B^{-}$  
\end{algorithmic}
\label{alg:setB}
\end{algorithm}

Метод обучается при помощи стохастического градиентного спуска.


\section{Эксперименты}

\subsection{Наборы данных}
В исследовании были использованы 4 разных набора данных.

\begin{itemize}
\item \textbf{Epinion} - социальная сеть, в которой публикуются покупательские отзывы и рецензии на товары и услуги. Каждый участник  решает кому он "доверяет". Следовательно, если пользователь $u$ "доверяет" пользователю $i$, то $R_{ui} = 1$

\item \textbf{Slashdot} - сайт, который предоставляет различные новости в сфере IT. Пользователи сами публикуют новости, в то время как другие пользователи их оценивают и обсуждают. Также данный сайт предоставляет возможность пользователям объявлять друг друга "врагом" или "другом".  $R_{ui}$ = 1, если пользователь $u$ является "другом" или "врагом" пользователя $i$.

\item \textbf{MovieLens} - сайт, в котором пользователи рекомендуют различные фильмы друг другу. Movielens предоставляет возможность ставить оценки фильмам. $R_{ui}$ = 1, если пользователь $u$ поставил оценки фильму $i$. В данной работе использованы два различных набора данных MovieLens: в первом 100000 оценок, во втором 1000000.

\end{itemize}

Перед тем как использовать наборы данных в экспериментах, из них были удалены пользователи, которые взаимодействовали с менее  25 предметами. Это было сделано для преодоления проблемы холодного старта, которым страдают факторизационные методы. 

Далее приведены статистические характеристики каждого набора данных после предобработки. 



\begin{table}[H]
\caption{\label{tab:canonsummary}Статистические характеристики}
\begin{center}
\begin{tabular}{|c|c c c c|}
\hline
Набор данных  & Epinion & Slashdot & MovieLens100k & MovieLens1m\\
\hline
Число ненулевых элементов & 326114 & 573578 & 96963  & 989202 \\
Число пользователей & 4405 & 6992 & 806 & 5549\\
Число предметов & 34777 & 63730 & 1682 & 3702\\
Плотность матрицы & 0.21\% & 0.13\% & 7.15 \% & 4.81 \% \\
Среднее число предметов у пользователя & 51  & 50 & 81 & 106\\
Максимальное число пользователей & 1801 & 2508 & 737 & 2314\\
у одного предмета.  & & & &\\
\hline
\end{tabular}
\end{center}
\end{table} 

\subsection{Сравнение методов}
 Сравним качество работы методов ранжирования друг с другом. Для этого проведем следующий эксперимент.
 
 Разобьем набор данных на тренировочную и тестовую выборку случайным образом. В тренировочной выборке у каждого пользователя будет givenK предметов. Остальные предметы лежат в тестовой выборке. Алгоритмы обучаются на тренировочной выборке, а качество работы измеряется на тестовой выборке. Далее такой эксперимент повторяется maxiter раз. Конечным результом является средняя величина качества работы по метрикам и алгоритмам. 
 

\begin{table}[H]
\caption{Набор данных Epinion}
%\begin{center}
\resizebox{0.8\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{givenk = 5, maxiter = 5} & \multicolumn{5}{|c|}{givenk = 10, maxiter = 5}\\
\hline
  & PopRec & CLiMF & BRP\_MF & iMF & TFMAP & PopRec & CLiMF & BRP\_MF & iMF & TFMAP  \\
\hline
P@5 & \textbf{0.1987}& 0.1962 &	0.1960 & 0.1876 & 0.1807 & 0.1837  & 0.1844 & 0.1846 & \textbf{0.2613} &	0.1808 \\
\hline
1call@5 & \textbf{0.5632} & 0.5448 & 0.5450 & 0.5509 & 0.5448 & 0.5189 & 0.5293 & 0.5241 &	\textbf{0.6383} & 0.5212\\
\hline
NDCG@5 & \textbf{0.2222} & 0.2205 & 0.2205 & 0.1980 & 0.2104 & 0.2061 & 0.2064 & 0.1909 &	\textbf{0.2725} &0.2041\\
\hline
MAP@5 & 0.3813 & 0.3769 & 0.3774 & 0.3356 & \textbf{0.3873} & 0.3568 & 0.3572 & 0.3120 &	\textbf{0.4121} & 0.3597\\
\hline
MRR & \textbf{0.4387} & 0.4368 & 0.4383 & 0.3818 & 0.4306 & 0.4113 & 0.4112 & 0.3480 & \textbf{0.4609} &	0.4114\\
\hline
AUC  & 0.8307 & 0.7512 & \textbf{0.8347} & 0.6915 & 0.6407 & 0.8558 & 0.8143 & \textbf{0.8591} &	0.8105 & 0.7310\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table} 


\begin{table}[H]
\caption{Набор данных Slashdot}
%\begin{center}
\resizebox{0.8\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{givenk = 5, maxiter = 5} & \multicolumn{5}{|c|}{givenk = 10, maxiter = 5}\\
\hline
  & PopRec & CLiMF & BRP\_MF & iMF & TFMAP & PopRec & CLiMF & BRP\_MF & iMF & TFMAP  \\
\hline
P@5 & 0.1225 & \textbf{0.1227} & 0.1210 & 0.1049 & 0.1153 &  0.1119 & 0.1118 & 0.1128 & \textbf{0.1358} & 0.1128 \\
\hline
1call@5 & \textbf{0.3765} & 0.3774 & 0.3761 & 0.3419 & 0.3592 & 0.3528 & 0.3528 & 0.3531 &	\textbf{0.3928} & 0.3544\\
\hline
NDCG@5 & \textbf{0.1319} & 0.1316 & 0.1309 & 0.1097 & 0.1244 & 0.1210 & 0.1210 & 0.1207 &	\textbf{0.1424} & 0.1215\\
\hline
MAP@5 & 0.2295 & 0.2289 & 	\textbf{0.2297}	& 0.1949 &	0.2194 &  0.2146 & 	0.2147 & 0.2110 &  \textbf{0.2374} &	0.2148\\
\hline
MRR & \textbf{0.2765} & 0.2755 &  0.2761 &  0.2343 &	0.2567 & 0.2602 & 0.2598  & 0.2558 & \textbf{0.2794} & 0.259429\\
\hline
AUC & 0.7770 &	0.6897 & \textbf{0.7850} & 0.5908 & 0.5973 &  0.8127	& 0.7582 & \textbf{0.8182} &	0.6925 & 0.6662\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table} 


\begin{table}[H]
\caption{Набор данных MobieLens 100k}
%\begin{center}
\resizebox{0.8\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{givenk = 5, maxiter = 5} & \multicolumn{5}{|c|}{givenk = 10, maxiter = 5}\\
\hline
  & PopRec & CLiMF & BRP\_MF & iMF & TFMAP & PopRec & CLiMF & BRP\_MF & iMF & TFMAP  \\
\hline
P@5 & \textbf{0.5309} & 0.5131 & 0.5303 & 0.4625 & 0.2624 &  0.4841 & 0.4821 &  0.4738 & \textbf{0.5307} & 0.4738 \\
\hline
1call@5 & \textbf{0.9431} & 0.9334 &	0.9374 & 0.8970 & 0.7461 & 0.9146 &	0.9141 & 0.9074 & \textbf{0.9292} &	0.8937\\
\hline
NDCG@5 & \textbf{0.5341} & 0.5171 &	0.5319 & 0.4756 & 0.3055 &  0.4934 & 0.4958 & 0.4725 &  \textbf{0.5369} &	0.4802\\
\hline
MAP@5 & \textbf{0.6703} & 0.6512 & 0.6636 & 0.6341 & 0.5452 & 0.6492 & 0.6568 & 0.6117 & \textbf{0.6741} &	0.6212\\
\hline
MRR & \textbf{0.7045} & 0.6970 &	0.7019 & 0.6818 & 0.5931 &  0.6885 & 0.6984 & 0.6474 &	\textbf{0.7139} & 0.6660\\
\hline
AUC & 0.8274 & 0.7572 &	\textbf{0.8288} & 0.6785 & 0.6366 &  0.8530 & 0.8405 & \textbf{0.8531} &	0.8285 & 0.7634\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table} 


\begin{table}[H]
\caption{Набор данных MobieLens 1m}
%\begin{center}
\resizebox{0.8\textwidth}{!}{\begin{minipage}{\textwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{5}{|c|}{givenk = 5, maxiter = 5} & \multicolumn{5}{|c|}{givenk = 10, maxiter = 5}\\
\hline
  & PopRec & CLiMF & BRP\_MF & iMF & TFMAP & PopRec & CLiMF & BRP\_MF & iMF & TFMAP  \\
\hline
P@5 & 0.4805 &	\textbf{0.4835} & 0.4797 & 0.4739 & 0.4138 &  0.4903 & 0.4903 &	0.4835 & \textbf{0.5739} & 0.4906\\
\hline
1call@5 & 0.8805 & 0.8704 & \textbf{0.8826} & 0.8707	& 0.8538 &  0.8610 & 0.8610 & 0.8479 & \textbf{0.9302} &	0.8587\\
\hline
NDCG@5 & \textbf{0.4935} & 0.4952 & 0.4923 &	0.4850 & 0.4515 & 0.5011 & 0.5011 &	0.4918 & \textbf{0.5838} & 0.5014\\
\hline
MAP@5 &0.6489 &	\textbf{0.6534} & 0.6484 & 0.6285 & 	0.6626 & 0.6557 & 0.6557 & 0.6151 &  \textbf{0.7088} & 0.6594 \\
\hline
MRR & \textbf{0.6941} & 0.6916 &	0.6930 & 0.6728 & 0.7019 & 0.6903 &	0.6903 & 0.6597 & \textbf{0.7530} & 0.6897\\
\hline
AUC & \textbf{0.8503} & 0.8286 &	0.8488 & 0.7185 & 0.7476 & \textbf{0.8561} &	0.8514 & 0.8556 & 0.8279 & 0.8043\\
\hline
\end{tabular}
\end{minipage}}
%\end{center}
\end{table} 



\newpage

	\begin{thebibliography}{00} % библиография
	\addcontentsline{toc}{section}{Список литературы}
    	\bibitem{climf}
    	
    	Yue Shi, Alexandros Karatzoglou, Linas Baltrunas.
    	
CLiMF: learning to maximize reciprocal rank with collaborative less-is-more filtering. 	
    	
    RecSys '12 the sixth ACM conference on Recommender systems, 2012.    	
    	
         \bibitem{bprmp}
         
	     Steffen Rendle, Christoph Freudenthaler, Zeno Gantner.    
         
         BPR: Bayesian Personalized Ranking from Implicit Feedback.
         
         UAI '09 Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, 2009
         
		\bibitem{tfmap}
		
		Yue Shia,Alexandros Karatzogloub, Linas Baltrunas.
		
TFMAP: Optimizing MAP for Top-N Context-aware Recommendation.		
		
		35th international ACM SIGIR conference on Research and development in Information Retrieval, 2012
		
	\bibitem{imf}
	Yifan Hu, Yehuda Koren, Chris Volinsky.
	
	Collaborative Filtering for Implicit Feedback Datasets.
	
	8th IEEE International Conference on Data Mining, 2008.
	
	
	\bibitem{matrixfactorization}
	Y. Koren, R. Bell, C. Volinsky.	
	
	Matrix Factorization Techniques for Recommender Systems.
	
	Computer IEEE, 2009
	\bibitem{netflix}
	Yehuda Koren
	
	The BellKor Solution to the Netflix Grand Prize. 
	
	2009


\end{thebibliography}
\end{document}
